{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347725a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ì´ í´ë” í•œë²ˆ ì‹¹ í›‘ì–´ë³´ê³  f1 macroì˜ ì ìˆ˜ë¥¼ ì¢€ë” ë†’ê²Œ ë°›ìœ¼ë ¤ë©´ ì–´ë–¤ë¶€ë¶„ì„ ê°œì„ í•´ì•¼í• ì§€ í•œë²ˆ ë§í•´ì¤„ìˆ˜ìˆì–´?\n",
    "\n",
    "Gemini\n",
    "ì•ˆë…•í•˜ì„¸ìš”! Gemini Code Assistì…ë‹ˆë‹¤. ì œì¶œí•˜ì‹  ì „ì²´ ì½”ë“œë¥¼ ê¼¼ê¼¼í•˜ê²Œ ê²€í† í–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ K-Fold êµì°¨ ê²€ì¦, TTA, ì•™ìƒë¸” ë“± ë§¤ìš° ìˆ˜ì¤€ ë†’ì€ ê¸°ë²•ë“¤ì„ ì˜ í™œìš©í•˜ê³  ê³„ì‹­ë‹ˆë‹¤. F1 Macro ì ìˆ˜ë¥¼ í•œ ë‹¨ê³„ ë” ëŒì–´ì˜¬ë¦¬ê¸° ìœ„í•œ ëª‡ ê°€ì§€ ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•´ ë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥\n",
    "í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê°•ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìƒì„¸í•œ EDA: korean_document_eda.pyë¥¼ í†µí•´ ë°ì´í„° ë¶ˆê· í˜•, ì´ë¯¸ì§€ í¬ê¸° ë“± í•µì‹¬ íŠ¹ì§•ì„ ì˜ íŒŒì•…í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "ì²´ê³„ì ì¸ í›ˆë ¨: main_test.pyì—ì„œ StratifiedKFoldë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ì¸ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "ê³ ê¸‰ ì¶”ë¡  ê¸°ë²•: inference.pyì™€ inference_ensemble.pyì—ì„œ TTAì™€ ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”ì„ êµ¬í˜„í•˜ì—¬ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "ì´ëŸ¬í•œ ê°•ì ì„ ë°”íƒ•ìœ¼ë¡œ, F1 Macro ì ìˆ˜ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì†Œìˆ˜ í´ë˜ìŠ¤(minority class)ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê³  ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶˜ ê°œì„ ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ¯ ê°œì„  ì œì•ˆ (F1 Macro ì ìˆ˜ í–¥ìƒ)\n",
    "1. K-Fold êµì°¨ ê²€ì¦ ê²°ê³¼ë¬¼ì„ í™œìš©í•œ ì•™ìƒë¸” (ê°€ì¥ íš¨ê³¼ì ì¸ ë°©ë²•)\n",
    "í˜„ì¬ main_test.pyì—ì„œ K-Fold í›ˆë ¨ì„ í•˜ê³  ìˆì§€ë§Œ, ê° Foldì—ì„œ ìƒì„±ëœ ëª¨ë¸ì„ ì•™ìƒë¸”ì— ì§ì ‘ í™œìš©í•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ê° Foldì˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ì„ ì•™ìƒë¸”í•˜ë©´ ë‹¨ì¼ ëª¨ë¸ì´ë‚˜ ì„œë¡œ ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ë¥¼ ì•™ìƒë¸”í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ì•ˆì •ì ì´ê³  ë†’ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤í–‰ ë°©ì•ˆ:\n",
    "\n",
    "main_test.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ê° Foldì˜ best-checkpointë¥¼ ëª¨ë‘ ì €ì¥í•©ë‹ˆë‹¤. (EfficientNetV2M_fold0_....pth, EfficientNetV2M_fold1_....pth, ...)\n",
    "inference_ensemble.pyë¥¼ ìˆ˜ì •í•˜ì—¬ ì´ ëª¨ë¸ë“¤ì„ ëª¨ë‘ ë¶ˆëŸ¬ì™€ ì¶”ë¡ í•˜ê³ , ê²°ê³¼ì˜ í‰ê· ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "inference_ensemble.py ìˆ˜ì • ì œì•ˆ:\n",
    "\n",
    "inference_ensemble.py\n",
    "-20\n",
    "+11\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from datasets.transforms import build_unified_transforms\n",
    "from utils.predict_tta import get_tta_predictions\n",
    "\n",
    "\n",
    "# --- ê¸°ë³¸ ì„¤ì • ---\n",
    "cfg = load_config(\"config/inference_config.yaml\")\n",
    "ModelClass_A = get_model(cfg['MODEL_A']['name'])\n",
    "ModelClass_B = get_model(cfg['MODEL_B']['name'])\n",
    "ModelClass_C = get_model(cfg['MODEL_C']['name'])\n",
    "ModelClass_D = get_model(cfg['MODEL_D']['name'])\n",
    "ModelClassList = [\n",
    "    ModelClass_A,\n",
    "    ModelClass_B,\n",
    "    ModelClass_C,\n",
    "]\n",
    "# K-Fold ì•™ìƒë¸”ì„ ìœ„í•´ ë‹¨ì¼ ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "ModelClass = get_model(cfg['MODEL']) # configì— ì•™ìƒë¸”í•  ëª¨ë¸ ì´ë¦„ ì¶”ê°€ í•„ìš” (ì˜ˆ: 'EfficientNetV2MArcFaceModel')\n",
    "DatasetClass = get_dataset(cfg['DATASET'])\n",
    "num_classes = 17\n",
    "num_workers = os.cpu_count() // 2\n",
    "\n",
    "# --- ì•™ìƒë¸” ì„¤ì • ---\n",
    "# 1. ì‚¬ìš©í•  ëª¨ë¸ë“¤ì˜ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "model_paths = [\n",
    "    f\"{output_root}/EfficientNetV2MArcFaceModel_2025-07-05_20-40_checkpoint.pth\",\n",
    "    f\"{output_root}/ResNeStModelArcFaceModel_2025-07-06_03-13_checkpoint.pth\",\n",
    "    f\"{output_root}/ConvNeXtArcFaceModel_2025-07-06_05-22_checkpoint.pth\",\n",
    "]\n",
    "# K-Foldë¡œ ìƒì„±ëœ ëª¨ë“  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "# ì˜ˆì‹œ: \"EfficientNetV2MArcFaceModel_fold*_checkpoint.pth\" íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ ê²€ìƒ‰\n",
    "model_pattern = f\"{cfg['MODEL']}_fold*_checkpoint.pth\" \n",
    "model_paths = glob.glob(os.path.join(output_root, model_pattern))\n",
    "print(f\"ë°œê²¬ëœ K-Fold ëª¨ë¸ {len(model_paths)}ê°œ: {model_paths}\")\n",
    "\n",
    "# ê°€ì¤‘ì¹˜ ë¦¬ìŠ¤íŠ¸ ì •ì˜\n",
    "# ëª¨ë¸ ê²½ë¡œ(model_paths) ìˆœì„œì™€ ë™ì¼í•˜ê²Œ ê°€ì¤‘ì¹˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "num_models = len(model_paths)\n",
    "use_weight = False\n",
    "if use_weight:\n",
    "    weights = [0.2, 0.4, 0.4]\n",
    "    # weights = [0.2, 0.3, 0.3, 0.2]\n",
    "    weights = [0.2, 0.2, 0.2, 0.2, 0.2] # Fold ê°œìˆ˜ì— ë§ê²Œ ìˆ˜ì •\n",
    "else:\n",
    "    weights = [1 / num_models] * num_models\n",
    "\n",
    "# --- ëª¨ë¸ ë¡œë“œ ---\n",
    "ensemble_models = []\n",
    "print(\"ì•™ìƒë¸” ëª¨ë¸ ë¡œë”© ì‹œì‘...\")\n",
    "for path, ModelClass in zip(model_paths, ModelClassList):\n",
    "    # ì£¼ì˜: ëª¨ë¸ ì•„í‚¤í…ì²˜ê°€ ë‹¤ë¥¼ ê²½ìš°, get_model ë“±ì„ í†µí•´ ê° ëª¨ë¸ì— ë§ëŠ” í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤.\n",
    "    model = ModelClass(num_classes).to(device)\n",
    "for path in model_paths:\n",
    "    model = ModelClass(num_classes=num_classes).to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.eval() # í‰ê°€ ëª¨ë“œë¡œ ì¦‰ì‹œ ì„¤ì •\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "2. ë°ì´í„° ë¶ˆê· í˜• ë¬¸ì œ ì‹¬ì¸µ í•´ê²°\n",
    "F1 Macro ì ìˆ˜ëŠ” ê° í´ë˜ìŠ¤ì˜ F1 ì ìˆ˜ì˜ ì‚°ìˆ  í‰ê· ì´ë¯€ë¡œ, ë°ì´í„°ê°€ ì ì€ í´ë˜ìŠ¤ì˜ ì„±ëŠ¥ì´ ì „ì²´ ì ìˆ˜ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. EDAì—ì„œ í™•ì¸ëœ ë°ì´í„° ë¶ˆê· í˜•ì„ í•´ê²°í•˜ëŠ” ê²ƒì´ ì ìˆ˜ í–¥ìƒì˜ í•µì‹¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤í–‰ ë°©ì•ˆ:\n",
    "\n",
    "Focal Loss ì‚¬ìš©: main.pyì—ì„œ get_loss í•¨ìˆ˜ë¥¼ í†µí•´ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ CrossEntropyLoss ëŒ€ì‹  Focal Lossë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”. Focal LossëŠ” ë§ì¶”ê¸° ì–´ë ¤ìš´ ìƒ˜í”Œ(ì£¼ë¡œ ì†Œìˆ˜ í´ë˜ìŠ¤)ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ëª¨ë¸ì´ ì†Œìˆ˜ í´ë˜ìŠ¤ì— ì§‘ì¤‘í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. config.yamlì—ì„œ ì†ì‹¤ í•¨ìˆ˜ ê´€ë ¨ ì„¤ì •ì„ ë³€ê²½í•˜ì—¬ ì‹¤í—˜í•´ ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
    "\n",
    "yaml\n",
    "# config/main_config.yaml ì˜ˆì‹œ\n",
    "loss:\n",
    "  name: \"FocalLoss\"\n",
    "  params:\n",
    "    alpha: 0.25\n",
    "    gamma: 2.0\n",
    "í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì ìš©: nn.CrossEntropyLossë¥¼ ì‚¬ìš©í•˜ë”ë¼ë„, í´ë˜ìŠ¤ë³„ ë°ì´í„° ìˆ˜ì˜ ì—­ìˆ˜ì— ë¹„ë¡€í•˜ëŠ” ê°€ì¤‘ì¹˜(weight ì¸ì)ë¥¼ ê³„ì‚°í•˜ì—¬ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ loss ì˜í–¥ë ¥ì„ ë†’ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "3. ë°ì´í„° ì¦ê°•(Augmentation) ê¸°ë²• ê³ ë„í™”\n",
    "ëª¨ë¸ì´ ë‹¤ì–‘í•œ í˜•íƒœì˜ ë¬¸ì„œ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•˜ê²Œ í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤í–‰ ë°©ì•ˆ:\n",
    "\n",
    "Mixup / CutMix ì ìš©: ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì„ ì¼ì • ë¹„ìœ¨ë¡œ ì„ëŠ” Mixupì´ë‚˜ ì´ë¯¸ì§€ì˜ ì¼ë¶€ë¥¼ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´í•˜ëŠ” CutMixëŠ” ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ê°•ê±´í•¨ì„ ë†’ì´ëŠ” ë° ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤. í›ˆë ¨ ë£¨í”„(trainer.pyì˜ training_loop) ë‚´ì—ì„œ ë°°ì¹˜ë¥¼ ë°›ì•„ ì²˜ë¦¬í•˜ëŠ” ë¶€ë¶„ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "test_data_preprocess.pyì˜ ì „ì²˜ë¦¬ ê¸°ë²•ì„ í›ˆë ¨ì—ë„ ì¼ë¶€ ì ìš©: test_data_preprocess.pyì—ì„œ ì‚¬ìš©í•œ ì™œê³¡ ë³´ì •, ëª…ì•” ì¡°ì ˆ ë“±ì˜ ê¸°ë²•ë“¤ì„ í›ˆë ¨ ì‹œ ë°ì´í„° ì¦ê°•ì˜ ì¼ë¶€ë¡œ í™•ë¥ ì ìœ¼ë¡œ ì ìš©(e.g., transforms.RandomApply)í•˜ë©´ í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë¶„í¬ ì°¨ì´ë¥¼ ì¤„ì—¬ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "4. ì½”ë“œ ë¦¬íŒ©í† ë§ ë° ê´€ë¦¬ íš¨ìœ¨ì„± ì¦ëŒ€\n",
    "main.py ì •ë¦¬: í˜„ì¬ main.py íŒŒì¼ì— DataLoaderê°€ ë‘ ë²ˆ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¤‘ë³µë˜ëŠ” ì½”ë“œë¥¼ ì œê±°í•˜ì—¬ ê°€ë…ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ë†’ì´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "í•˜ë“œì½”ë”©ëœ ê²½ë¡œ ì œê±°: inference_ensemble.pyì— ëª¨ë¸ ê²½ë¡œê°€ í•˜ë“œì½”ë”©ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ì œì•ˆí•œ ê²ƒì²˜ëŸ¼ globì„ ì‚¬ìš©í•˜ê±°ë‚˜, í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ìƒì„±ëœ ëª¨ë¸ ê²½ë¡œë“¤ì„ ë³„ë„ì˜ ì„¤ì • íŒŒì¼ì´ë‚˜ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡í•˜ê³  ì¶”ë¡  ì‹œ ì´ë¥¼ ì½ì–´ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ ìë™í™”í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
    "ê°€ì¥ ë¨¼ì € main_test.pyë¥¼ í™œìš©í•œ K-Fold í›ˆë ¨ ë° ì•™ìƒë¸”(ì œì•ˆ 1)ì„ ì‹œë„í•´ ë³´ì„¸ìš”. ê°€ì¥ í° ì„±ëŠ¥ í–¥ìƒì„ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "ê·¸ë‹¤ìŒ, **Focal Lossë¥¼ ì ìš©(ì œì•ˆ 2)**í•˜ì—¬ ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ì‹¤í—˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "ì¶”ê°€ì ì¸ ì„±ëŠ¥ í–¥ìƒì´ í•„ìš”í•  ë•Œ **Mixup/CutMixì™€ ê°™ì€ ê³ ê¸‰ ì¦ê°• ê¸°ë²•(ì œì•ˆ 3)**ì„ ë„ì…í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ ë³´ì„¸ìš”.\n",
    "ì´ ì œì•ˆë“¤ì´ F1 Macro ì ìˆ˜ë¥¼ ë†’ì´ëŠ” ë° ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤. ì„±ê³µì ì¸ ê²°ê³¼ ìˆê¸°ë¥¼ ì‘ì›í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65dabab",
   "metadata": {},
   "source": [
    "ì´ í´ë” í•œë²ˆ ì‹¹ í›‘ì–´ë³´ê³  f1 macroì˜ ì ìˆ˜ë¥¼ ì¢€ë” ë†’ê²Œ ë°›ìœ¼ë ¤ë©´ ì–´ë–¤ë¶€ë¶„ì„ ê°œì„ í•´ì•¼í• ì§€ í•œë²ˆ ë§í•´ì¤„ìˆ˜ìˆì–´?\n",
    "\n",
    "\n",
    "Gemini\n",
    "ì•ˆë…•í•˜ì„¸ìš”! Gemini Code Assistì…ë‹ˆë‹¤. ì œì¶œí•˜ì‹  ì „ì²´ ì½”ë“œë¥¼ ê¼¼ê¼¼í•˜ê²Œ ê²€í† í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. K-Fold êµì°¨ ê²€ì¦, TTA, ì•™ìƒë¸” ë“± ì´ë¯¸ í›Œë¥­í•œ ê¸°ë²•ë“¤ì„ ë§ì´ ì ìš©í•˜ê³  ê³„ì‹œë„¤ìš”. í˜„ì¬ êµ¬ì¡°ì—ì„œ F1 Macro ì ìˆ˜ë¥¼ ë” ë†’ì´ê¸° ìœ„í•´ ì‹œë„í•´ ë³¼ ë§Œí•œ ëª‡ ê°€ì§€ ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•´ ë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "ì¢…í•© í‰ê°€ ë° ê°œì„  ë°©í–¥\n",
    "F1 Macro ì ìˆ˜ëŠ” ê° í´ë˜ìŠ¤ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ í‰ê· ì„ ë‚´ê¸° ë•Œë¬¸ì—, ë°ì´í„°ê°€ ì ì€ í´ë˜ìŠ¤(minority class)ì˜ ì„±ëŠ¥ì´ ì „ì²´ ì ìˆ˜ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë”°ë¼ì„œ ê°œì„ ì˜ í•µì‹¬ì€ **\"ë°ì´í„° ë¶ˆê· í˜• ë¬¸ì œë¥¼ ì–¼ë§ˆë‚˜ ì˜ í•´ê²°í•˜ê³ , ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ”ê°€\"**ì— ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ğŸ¯ ì£¼ìš” ê°œì„  ì œì•ˆ (F1 Macro ì ìˆ˜ í–¥ìƒ ì´ˆì )\n",
    "1. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ ì‹¬ì¸µ í•´ê²°: Focal Loss ë„ì…\n",
    "í˜„ì¬ main.pyì—ì„œ samplerë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ì¼ë¶€ ì™„í™”í•˜ê³  ìˆì§€ë§Œ, ì´ê²ƒë§Œìœ¼ë¡œëŠ” ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë¶„ë¥˜í•˜ê¸° ì–´ë ¤ìš´(hard-to-classify) ìƒ˜í”Œì— ë” ì§‘ì¤‘í•˜ì—¬ í•™ìŠµí•˜ëŠ” Focal Lossë¥¼ ë„ì…í•˜ëŠ” ê²ƒì„ ê°•ë ¥íˆ ì¶”ì²œí•©ë‹ˆë‹¤. Focal LossëŠ” ë§ì¶”ê¸° ì‰¬ìš´ ë‹¤ìˆ˜ í´ë˜ìŠ¤(majority class) ìƒ˜í”Œë“¤ì˜ loss ê¸°ì—¬ë„ë¥¼ ë‚®ì¶”ê³ , ë§ì¶”ê¸° ì–´ë ¤ìš´ ì†Œìˆ˜ í´ë˜ìŠ¤ ìƒ˜í”Œì— ë” ì§‘ì¤‘í•˜ê²Œ ë§Œë“¤ì–´ F1 Macro ì ìˆ˜ í–¥ìƒì— ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "main.pyì˜ get_loss í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë¯€ë¡œ, loss_factory.pyì— Focal Lossë¥¼ ì¶”ê°€í•˜ê³  main_config.yamlì—ì„œ ì†ì‰½ê²Œ ë³€ê²½í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆì‹œ (loss_factory.pyì— Focal Loss ì¶”ê°€):\n",
    "\n",
    "python\n",
    "# utils/loss_factory.py (ê°€ìƒ ê²½ë¡œ)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "def get_loss(name, params):\n",
    "    if name == \"CrossEntropyLoss\":\n",
    "        return nn.CrossEntropyLoss(**params)\n",
    "    elif name == \"FocalLoss\":\n",
    "        return FocalLoss(**params)\n",
    "    # ... ë‹¤ë¥¸ ì†ì‹¤ í•¨ìˆ˜ë“¤\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss function: {name}\")\n",
    "ì ìš© (main_config.yaml ìˆ˜ì •):\n",
    "\n",
    "yaml\n",
    "# config/main_config.yaml\n",
    "loss:\n",
    "  # name: \"CrossEntropyLoss\"\n",
    "  # params: {}\n",
    "  name: \"FocalLoss\"\n",
    "  params:\n",
    "    alpha: 0.25\n",
    "    gamma: 2.0\n",
    "2. K-Fold êµì°¨ ê²€ì¦ê³¼ ì•™ìƒë¸”ì˜ ê²°í•©\n",
    "main_test.pyì—ì„œ K-Foldë¥¼ êµ¬í˜„í•˜ì…¨ê³ , inference_ensemble.pyì—ì„œ ì—¬ëŸ¬ ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë‘ ê°€ì§€ ê°•ë ¥í•œ ê¸°ë²•ì„ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í˜„ì¬ ë°©ì‹:\n",
    "\n",
    "Model A, B, Cë¥¼ ê°ê° í•œ ë²ˆì”© í•™ìŠµ -> 3ê°œ ëª¨ë¸ ì•™ìƒë¸”\n",
    "ì œì•ˆ ë°©ì‹:\n",
    "\n",
    "5-Fold êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •\n",
    "Model Aë¥¼ 5-Foldë¡œ í•™ìŠµ -> 5ê°œì˜ Model A ì²´í¬í¬ì¸íŠ¸ ìƒì„±\n",
    "Model Bë¥¼ 5-Foldë¡œ í•™ìŠµ -> 5ê°œì˜ Model B ì²´í¬í¬ì¸íŠ¸ ìƒì„±\n",
    "Model Cë¥¼ 5-Foldë¡œ í•™ìŠµ -> 5ê°œì˜ Model C ì²´í¬í¬ì¸íŠ¸ ìƒì„±\n",
    "ì´ 15ê°œì˜ ëª¨ë¸ì„ ëª¨ë‘ ì•™ìƒë¸”í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "ì´ë ‡ê²Œ í•˜ë©´ ë°ì´í„°ì…‹ì„ í›¨ì”¬ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•˜ê²Œ ë˜ì–´ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ê³ , ë‹¨ì¼ ëª¨ë¸ì˜ ë¶„ì‚°(variance)ì„ ì¤„ì—¬ì£¼ì–´ ìµœì¢… ì•™ìƒë¸” ê²°ê³¼ê°€ í›¨ì”¬ ì•ˆì •ì ì´ê³  ê°•ë ¥í•´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ë¡œì§ ì˜¤ë¥˜ ìˆ˜ì •\n",
    "test_data_preprocess.py ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‹¬ê°í•œ ë…¼ë¦¬ì  ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ì–´ë–¤ ì „ì²˜ë¦¬ë¥¼ ì ìš©í• ì§€ ê²°ì •í•˜ê¸° ìœ„í•´ sample_submission.csvì˜ target ê°’ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "python\n",
    "# /root/DTC/upstageailab-cv-classification-cv_6/test_data_preprocess.py\n",
    "...\n",
    "    # CSV íŒŒì¼ ì½ê¸°\n",
    "    df = pd.read_csv(input_csv) # input_csv = './data/sample_submission.csv'\n",
    "...\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = row['ID']\n",
    "        target = row['target'] # <-- ë¬¸ì œ ì§€ì \n",
    "...\n",
    "        # í´ë˜ìŠ¤ê°€ ì§€ì •ëœ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê²½ìš° ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "        if target in classes_to_crop: # <-- ë¬¸ì œ ì§€ì \n",
    "            processed_image = process_image(image_path)\n",
    "...\n",
    "sample_submission.csvì˜ targetì€ ì‹¤ì œ ì •ë‹µì´ ì•„ë‹Œ, ì œì¶œ í˜•ì‹ì„ ìœ„í•œ ì„ì˜ì˜ ê°’ì…ë‹ˆë‹¤. ì‹¤ì œ í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œëŠ” ì •ë‹µ(target)ì„ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì´ ë¡œì§ì€ ë™ì‘í•  ìˆ˜ ì—†ìœ¼ë©°, í˜„ì¬ëŠ” ìš°ì—°íˆ sample_submissionì˜ ê°’ì— ë”°ë¼ ì „ì²˜ë¦¬ê°€ ì ìš©ë˜ê³  ìˆì„ ë¿ì…ë‹ˆë‹¤.\n",
    "\n",
    "í•´ê²° ë°©ì•ˆ: ëª¨ë“  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ë™ì¼í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹ì • í´ë˜ìŠ¤ì—ë§Œ ë‹¤ë¥¸ ì „ì²˜ë¦¬ë¥¼ ì ìš©í•˜ê³  ì‹¶ë‹¤ë©´, ê·¸ ê²°ì •ì€ ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ(ì˜ˆ: 1ë‹¨ê³„ ë¶„ë¥˜ ëª¨ë¸) í•´ì•¼ í•˜ë©° ì™¸ë¶€ ì •ë³´(ì •ë‹µ)ì— ì˜ì¡´í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ê°€ì¥ ê°„ë‹¨í•˜ê³  ì˜¬ë°”ë¥¸ ìˆ˜ì •ì€ ì¡°ê±´ë¬¸ì„ ì œê±°í•˜ê³  ëª¨ë“  ì´ë¯¸ì§€ì— ì¼ê´€ëœ ì „ì²˜ë¦¬ë¥¼ ì ìš©í•˜ê±°ë‚˜, í˜¹ì€ ì „ì²˜ë¦¬ê°€ ë¶ˆí•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´ ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ëª¨ë“  ì´ë¯¸ì§€ì— process_imageë¥¼ ì ìš©í•˜ëŠ” ìˆ˜ì •ì•ˆì…ë‹ˆë‹¤.\n",
    "\n",
    "test_data_preprocess.py\n",
    "-39\n",
    "+32\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # í¬ë¡­í•  í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
    "    classes_to_crop = [1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15]\n",
    "    \"\"\"\n",
    "    0,ê³„ì¢Œë²ˆí˜¸\n",
    "    1,ì§€ê¸‰ ì‹ ì²­ì„œ\n",
    "    2,ìë™ì°¨ ê³„ê¸°íŒ\n",
    "    3,ì…_í‡´ì› í™•ì¸ì„œ\n",
    "    4,ì§„ë‹¨ì„œ\n",
    "    5,ìš´ì „ë©´í—ˆì¦\n",
    "    6,ì§„ë£Œë¹„ì˜ìˆ˜ì¦\n",
    "    7,í†µì›_ì§„ë£Œ í™•ì¸ì„œ\n",
    "    8,ì£¼ë¯¼ë“±ë¡ì¦\n",
    "    9,ì—¬ê¶Œ\n",
    "    10,ì§„ë£Œë¹„_ë‚©ì…_í™•ì¸ì„œ\n",
    "    11,ì•½ì œë¹„_ì˜ìˆ˜ì¦\n",
    "    12,ì²˜ë°©ì „\n",
    "    13,ì´ë ¥ì„œ\n",
    "    14,ì†Œê²¬ì„œ\n",
    "    15,ìë™ì°¨_ë“±ë¡ì¦\n",
    "    16,ìë™ì°¨_ë²ˆí˜¸íŒ\n",
    "    \"\"\"\n",
    "\n",
    "    # CSV íŒŒì¼ ì½ê¸°\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    processed_data = []\n",
    "\n",
    "    # ê° í–‰ì— ëŒ€í•´ ë°˜ë³µ\n",
    "    for index, row in df.iterrows():\n",
    "    # for index, row in df.iterrows():\n",
    "    #     file_name = row['ID']\n",
    "    #     target = row['target']\n",
    "    #     image_path = os.path.join(input_dir, file_name)\n",
    "    #     print(f\"Processing image: {index} - {file_name}\")\n",
    "\n",
    "    #     # í´ë˜ìŠ¤ê°€ ì§€ì •ëœ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê²½ìš° ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "    #     if target in classes_to_crop:\n",
    "    #         processed_image = process_image(image_path)\n",
    "    #         processed_image_path = os.path.join(output_dir, file_name)\n",
    "    #         cv2.imwrite(processed_image_path, processed_image)\n",
    "            \n",
    "    #         # ìƒˆë¡œìš´ CSV íŒŒì¼ì— ê¸°ë¡í•  ë°ì´í„° ì¶”ê°€\n",
    "    #         processed_data.append({'ID': file_name, 'target': target})\n",
    "    #     else:\n",
    "    #         # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬\n",
    "    #         image = load_image(image_path)\n",
    "    #         processed_image_path = os.path.join(output_dir, file_name)\n",
    "    #         cv2.imwrite(processed_image_path, image)\n",
    "            \n",
    "    #         # ì²˜ë¦¬í•˜ì§€ ì•Šì€ ë°ì´í„°ë„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    #         processed_data.append({'ID': file_name, 'target': target})\n",
    "    \n",
    "    # ëª¨ë“  ì´ë¯¸ì§€ì— ì¼ê´€ëœ ì „ì²˜ë¦¬ ì ìš©\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = row['ID']\n",
    "        target = row['target']\n",
    "        image_path = os.path.join(input_dir, file_name)\n",
    "        print(f\"Processing image: {index} - {file_name}\")\n",
    "\n",
    "        # í´ë˜ìŠ¤ê°€ ì§€ì •ëœ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê²½ìš° ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "        if target in classes_to_crop:\n",
    "            processed_image = process_image(image_path)\n",
    "            processed_image_path = os.path.join(output_dir, file_name)\n",
    "            cv2.imwrite(processed_image_path, processed_image)\n",
    "            \n",
    "            # ìƒˆë¡œìš´ CSV íŒŒì¼ì— ê¸°ë¡í•  ë°ì´í„° ì¶”ê°€\n",
    "            processed_data.append({'ID': file_name, 'target': target})\n",
    "        else:\n",
    "            # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬\n",
    "            image = load_image(image_path)\n",
    "            processed_image_path = os.path.join(output_dir, file_name)\n",
    "            cv2.imwrite(processed_image_path, image)\n",
    "            \n",
    "            # ì²˜ë¦¬í•˜ì§€ ì•Šì€ ë°ì´í„°ë„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            processed_data.append({'ID': file_name, 'target': target})\n",
    "        # ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "        processed_image = process_image(image_path)\n",
    "        processed_image_path = os.path.join(output_dir, file_name)\n",
    "        cv2.imwrite(processed_image_path, processed_image)\n",
    "        \n",
    "        # ìƒˆë¡œìš´ CSV íŒŒì¼ì— ê¸°ë¡í•  ë°ì´í„° ì¶”ê°€\n",
    "        processed_data.append({'ID': file_name, 'target': target})\n",
    "\n",
    "    print(f\"ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ {output_dir}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "4. ì½”ë“œ ë¦¬íŒ©í† ë§ ë° ì •ë¦¬\n",
    "main.py íŒŒì¼ì— ì•½ê°„ì˜ ì¤‘ë³µ ì½”ë“œì™€ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤. ì½”ë“œë¥¼ ì •ë¦¬í•˜ë©´ ì‹¤ìˆ˜ë¥¼ ì¤„ì´ê³  ìœ ì§€ë³´ìˆ˜ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì¤‘ë³µ DataLoader ì •ì˜: train_loaderì™€ val_loaderê°€ ë‘ ë²ˆ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì •ì˜ëŠ” samplerë¥¼ ì‚¬ìš©í•˜ê³ , ë‘ ë²ˆì§¸ ì •ì˜ëŠ” shuffle=Trueë¥¼ ì‚¬ìš©í•˜ë©° num_workersì™€ prefetch_factorê°€ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ë„í•œ ì„¤ì •ì„ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ì‚­ì œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” í•¨ìˆ˜: train_block, just_one_train, n_fold_train í•¨ìˆ˜ë“¤ì´ ì •ì˜ë˜ì–´ ìˆì§€ë§Œ ì‹¤ì œ if __name__ == \"__main__\": ë¸”ë¡ì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. main_test.pyì˜ run_foldì²˜ëŸ¼ ëª¨ë“ˆí™”í•˜ë ¤ëŠ” ì˜ë„ì˜€ë‹¤ë©´ êµ¬ì¡°ë¥¼ ì™„ì„±í•˜ê±°ë‚˜, ì•„ë‹ˆë¼ë©´ í˜¼ë™ì„ í”¼í•˜ê¸° ìœ„í•´ ì‚­ì œí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "main.py\n",
    "-85\n",
    "+0\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=cfg[\"BATCH_SIZE\"],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg[\"BATCH_SIZE\"],\n",
    "    shuffle=True,\n",
    "    num_workers=24,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=cfg[\"BATCH_SIZE\"],\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "\n",
    "def unfreeze(model: nn.Module) -> nn.Parameter:\n",
    "    # 1. ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ìš°ì„  ë™ê²°(freeze)í•©ë‹ˆë‹¤.\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 2. íŠ¹ì§• ì¶”ì¶œê¸°(backbone)ì˜ ë§ˆì§€ë§‰ nê°œ ë¸”ë¡ì˜ ë™ê²°ì„ í•´ì œ(unfreeze)í•©ë‹ˆë‹¤.\n",
    "    # efficientnet_b3ëŠ” 7ê°œì˜ ë¸”ë¡(0~6)ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
    "    for i in range(cfg[\"num_blocks_to_unfreeze\"]):\n",
    "        for param in model.backbone.blocks[-(i+1)].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # 3. ë¶„ë¥˜ê¸°(head)ì˜ ë™ê²°ì„ í•´ì œí•©ë‹ˆë‹¤.\n",
    "    for param in model.head.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # 4. í•™ìŠµì‹œí‚¬ íŒŒë¼ë¯¸í„°ë§Œ í•„í„°ë§í•˜ì—¬ ì˜µí‹°ë§ˆì´ì €ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "    # requires_grad=Trueì¸ íŒŒë¼ë¯¸í„°ë§Œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.\n",
    "    params_to_update = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    \n",
    "    return params_to_update\n",
    "\n",
    "\n",
    "def train_block():\n",
    "    \n",
    "    # load model\n",
    "    model: nn.Module = ModelClass(num_classes=num_classes).to(device)\n",
    "    \n",
    "    if cfg[\"use_unfreeze\"]:\n",
    "        params_to_update = unfreeze(model)\n",
    "    else:\n",
    "        params_to_update = model.parameters()\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=cfg[\"patience\"], delta=cfg[\"delta\"], verbose=True, save_path=save_path, mode='max')\n",
    "\n",
    "    # ì†ì‹¤ í•¨ìˆ˜\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ì˜µí‹°ë§ˆì´ì €\n",
    "    optimizer = get_optimizer(cfg_optimizer[\"name\"], params_to_update, cfg_optimizer[\"params\"])\n",
    "\n",
    "    # ìŠ¤ì¼€ì¥´ëŸ¬\n",
    "    Scheduler = get_scheduler(cfg_scheduler[\"name\"], optimizer, cfg_scheduler['params'])\n",
    "\n",
    "    # ampë¥¼ ìœ„í•œ scaler ì¤€ë¹„\n",
    "    training_args = {}\n",
    "    if cfg[\"training_mode\"] == 'on_amp':\n",
    "        training_args['scaler'] = GradScaler()\n",
    "\n",
    "    model, valid_max_accuracy = training_loop(\n",
    "        training_fn,\n",
    "        model, train_loader, val_loader, train_dataset, val_dataset, \n",
    "        criterion, optimizer, device, cfg[\"EPOCHS\"], \n",
    "        early_stopping, logger, class_names, Scheduler,\n",
    "        training_args,\n",
    "        )\n",
    "    return model, valid_max_accuracy\n",
    "\n",
    "    \n",
    "def just_one_train():\n",
    "    pass\n",
    "\n",
    "\n",
    "def n_fold_train():\n",
    "    pass\n",
    "\n",
    "\n",
    "def setup_optimizer_params(\n",
    "    model: nn.Module, \n",
    "\n",
    "ìš”ì•½\n",
    "1ìˆœìœ„ (ì„±ëŠ¥ í–¥ìƒ): Focal Lossë¥¼ ë„ì…í•˜ì—¬ ì†Œìˆ˜ í´ë˜ìŠ¤ í•™ìŠµì„ ê°•í™”í•˜ì„¸ìš”.\n",
    "2ìˆœìœ„ (ì„±ëŠ¥ í–¥ìƒ): K-Foldì™€ ì•™ìƒë¸”ì„ ê²°í•©í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ê·¹ëŒ€í™”í•˜ì„¸ìš”.\n",
    "3ìˆœìœ„ (ì˜¤ë¥˜ ìˆ˜ì •): í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œ targetì„ ì‚¬ìš©í•˜ëŠ” ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "4ìˆœìœ„ (ì½”ë“œ í’ˆì§ˆ): main.pyì˜ ì¤‘ë³µ ì½”ë“œë¥¼ ì •ë¦¬í•˜ì—¬ ì ì¬ì ì¸ ë²„ê·¸ë¥¼ ë°©ì§€í•˜ì„¸ìš”.\n",
    "ì´ ì œì•ˆë“¤ì´ F1 Macro ì ìˆ˜ë¥¼ í•œ ë‹¨ê³„ ë” ëŒì–´ì˜¬ë¦¬ëŠ” ë° ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06eb42c",
   "metadata": {},
   "source": [
    "ì¶”ê°€ë¡œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë” ì˜ë‚˜ì˜¤ê²Œ ì„¤ì • í•´ë´ì¤„ìˆ˜ìˆì–´?\n",
    "\n",
    "\n",
    "Gemini\n",
    "ì•ˆë…•í•˜ì„¸ìš”! ë¬¼ë¡ ì…ë‹ˆë‹¤. í˜„ì¬ main.pyì— êµ¬í˜„ëœ ì°¨ë“± í•™ìŠµë¥ (differential learning rate) ì„¤ì •ì€ ë§¤ìš° ì¢‹ì€ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ í•œ ê±¸ìŒ ë” ë‚˜ì•„ê°€, ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹(Staged Fine-tuning) ì „ëµê³¼ í•¨ê»˜ íŒŒë¼ë¯¸í„° ì„¤ì • ì½”ë“œë¥¼ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•´ ë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "í•µì‹¬ ê°œì„  ì•„ì´ë””ì–´: ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹ (Staged Fine-tuning)\n",
    "í˜„ì¬ëŠ” ëª¨ë¸ì˜ í—¤ë“œì™€ ë°±ë³¸ ì¼ë¶€ë¥¼ ì²˜ìŒë¶€í„° í•¨ê»˜ í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì‚¬ì „ í•™ìŠµëœ ë°±ë³¸ì˜ ê°€ì¤‘ì¹˜ëŠ” ë§¤ìš° ìœ ìš©í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ”ë°, ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ëœ í—¤ë“œ(head)ì˜ í° ê·¸ë˜ë””ì–¸íŠ¸ ë•Œë¬¸ì— ì´ ì •ë³´ê°€ ì´ˆë°˜ì— ì†ìƒë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹ì€ ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” íš¨ê³¼ì ì¸ ì „ëµì…ë‹ˆë‹¤.\n",
    "\n",
    "1ë‹¨ê³„: í—¤ë“œ í•™ìŠµ (Feature Extraction)\n",
    "\n",
    "ë°±ë³¸(backbone)ì€ ì™„ì „íˆ ë™ê²°(freeze)í•˜ê³ , ìƒˆë¡œìš´ ë°ì´í„°ì— ë§ê²Œ í—¤ë“œë§Œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "ì´ë¥¼ í†µí•´ ë°±ë³¸ì˜ ì‚¬ì „ í•™ìŠµëœ íŠ¹ì§•ì„ ê·¸ëŒ€ë¡œ í™œìš©í•˜ë©´ì„œ, ìƒˆë¡œìš´ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë°©ë²•ë§Œ ë¹ ë¥´ê²Œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "2ë‹¨ê³„: ì „ì²´ ë¯¸ì„¸ ì¡°ì • (Fine-tuning)\n",
    "\n",
    "í—¤ë“œê°€ ì–´ëŠ ì •ë„ ì•ˆì •ë˜ë©´, ë°±ë³¸ì˜ ë™ê²°ì„ ì¼ë¶€ ë˜ëŠ” ì „ì²´ í•´ì œí•©ë‹ˆë‹¤.\n",
    "ì´í›„, ë°±ë³¸ì—ëŠ” ë‚®ì€ í•™ìŠµë¥ (learning rate)ì„, í—¤ë“œì—ëŠ” ë” ë†’ì€ í•™ìŠµë¥ ì„ ì ìš©í•˜ëŠ” ì°¨ë“± í•™ìŠµë¥ ë¡œ ëª¨ë¸ ì „ì²´ë¥¼ ë¶€ë“œëŸ½ê²Œ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "ì´ ë°©ì‹ì„ í†µí•´ í•™ìŠµ ì•ˆì •ì„±ì„ ë†’ì´ê³ , ëª¨ë¸ì´ ë°ì´í„°ì˜ íŠ¹ì§•ì„ ë” ì˜ í•™ìŠµí•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ ë” ë†’ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ğŸ’» ì½”ë“œ ê°œì„  ì œì•ˆ\n",
    "ìœ„ ì „ëµì„ ì ìš©í•˜ê¸° ìœ„í•´ main.pyì˜ íŒŒë¼ë¯¸í„° ì„¤ì • í•¨ìˆ˜ì™€ ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ì„ ë‹¤ìŒê³¼ ê°™ì´ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. setup_optimizer_params í•¨ìˆ˜ ê°œì„ \n",
    "ê¸°ì¡´ í•¨ìˆ˜ë¥¼ ì¡°ê¸ˆ ë” ìœ ì—°í•˜ê³  ì•ˆì •ì ìœ¼ë¡œ ë§Œë“¤ì–´, ì–´ë–¤ ëª¨ë¸ êµ¬ì¡°ì—ë„ ì˜ ëŒ€ì‘í•˜ê³  ë‹¨ê³„ë³„ í•™ìŠµì„ ì œì–´í•˜ê¸° ì‰½ê²Œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
    "\n",
    "model.neckì´ ì—†ëŠ” ê²½ìš°ì—ë„ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ hasattr ì²´í¬ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "íŒŒë¼ë¯¸í„° ê·¸ë£¹ì„ ìƒì„±í•  ë•Œ ë¹ˆ ê·¸ë£¹ì´ ì¶”ê°€ë˜ì§€ ì•Šë„ë¡ í•„í„°ë§ ë¡œì§ì„ ê°•í™”í•©ë‹ˆë‹¤.\n",
    "2. main.py ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ìˆ˜ì •\n",
    "if __name__ == \"__main__\": ë¶€ë¶„ì„ 2ë‹¨ê³„ í•™ìŠµ ë¡œì§ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
    "\n",
    "1ë‹¨ê³„ í•™ìŠµ ë£¨í”„: num_layers_to_unfreeze=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í—¤ë“œë§Œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "2ë‹¨ê³„ í•™ìŠµ ë£¨í”„: num_layers_to_unfreezeë¥¼ ì„¤ì • íŒŒì¼ ê°’ìœ¼ë¡œ í•˜ì—¬ ì „ì²´ë¥¼ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "ê° ë‹¨ê³„ì— ë§ëŠ” ì˜µí‹°ë§ˆì´ì €ì™€ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "ì•„ë˜ëŠ” ìœ„ ë‚´ìš©ì„ ë°˜ì˜í•œ main.pyì˜ ì „ì²´ ì½”ë“œ ë³€ê²½ ì œì•ˆì…ë‹ˆë‹¤.\n",
    "\n",
    "main.py\n",
    "-79\n",
    "+98\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=cfg[\"BATCH_SIZE\"],\n",
    "    shuffle=True,\n",
    "    num_workers=24,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "\n",
    "\n",
    "def setup_optimizer_params(\n",
    "    model: nn.Module, \n",
    "    model_type: str, \n",
    "    num_layers_to_unfreeze: int,\n",
    "    backbone_lr: float,\n",
    "    head_lr: float,\n",
    "    use_differential_lr: bool,\n",
    "):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ì˜ ë™ê²°/í•´ì œ ìƒíƒœë¥¼ ì„¤ì •í•˜ê³ , ì°¨ë“± í•™ìŠµë¥ ì„ ì ìš©í•  íŒŒë¼ë¯¸í„° ê·¸ë£¹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=cfg[\"BATCH_SIZE\"],\n",
    "    shuffle=False, # ê²€ì¦ ë°ì´í„°ëŠ” ë³´í†µ ì„ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "def setup_optimizer_params(model: nn.Module, model_type: str, num_layers_to_unfreeze: int, backbone_lr: float, head_lr: float, use_differential_lr: bool):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ì˜ ë™ê²°/í•´ì œ ìƒíƒœë¥¼ ì„¤ì •í•˜ê³ , ì°¨ë“± í•™ìŠµë¥ ì„ ì ìš©í•  íŒŒë¼ë¯¸í„° ê·¸ë£¹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "    :param model: ì„¤ì •í•  PyTorch ëª¨ë¸ ê°ì²´\n",
    "    :param model_type: ëª¨ë¸ì˜ ì¢…ë¥˜ ('resnet', 'efficientnet', 'swin', 'convnext')\n",
    "    :param backbone_lr: ë°±ë³¸ì— ì ìš©í•  ë‚®ì€ í•™ìŠµë¥ \n",
    "    :param head_lr: ë„¥/í—¤ë“œì— ì ìš©í•  ë†’ì€ í•™ìŠµë¥ \n",
    "    :return: ì˜µí‹°ë§ˆì´ì €ì— ì „ë‹¬í•  íŒŒë¼ë¯¸í„° ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    # 1. ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ìš°ì„  ë™ê²°(freeze)í•©ë‹ˆë‹¤.\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    backbone = model.backbone\n",
    "    \n",
    "    stages_to_unfreeze = []\n",
    "    if model_type_lower.startswith('resnet'):\n",
    "        all_stages = [backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4]\n",
    "        if num_layers_to_unfreeze > len(all_stages):\n",
    "            num_layers_to_unfreeze = len(all_stages)\n",
    "        stages_to_unfreeze = all_stages[-num_layers_to_unfreeze:]\n",
    "    elif model_type_lower.startswith(('efficientnet', 'swin', 'convnext')):\n",
    "        if model_type_lower.startswith('swin'): all_stages = backbone.layers\n",
    "        elif model_type_lower.startswith('convnext'): all_stages = backbone.stages\n",
    "        else: all_stages = backbone.blocks\n",
    "        num_total_blocks = len(all_stages)\n",
    "        if num_layers_to_unfreeze > num_total_blocks:\n",
    "            num_layers_to_unfreeze = num_total_blocks\n",
    "        stages_to_unfreeze = all_stages[-num_layers_to_unfreeze:]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model_type: {model_type}.\")\n",
    "    if num_layers_to_unfreeze > 0:\n",
    "        if model_type_lower.startswith('resnet'):\n",
    "            all_stages = [backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4]\n",
    "            if num_layers_to_unfreeze > len(all_stages):\n",
    "                num_layers_to_unfreeze = len(all_stages)\n",
    "            stages_to_unfreeze = all_stages[-num_layers_to_unfreeze:]\n",
    "        elif model_type_lower.startswith(('efficientnet', 'swin', 'convnext')):\n",
    "            if model_type_lower.startswith('swin'): all_stages = backbone.layers\n",
    "            elif model_type_lower.startswith('convnext'): all_stages = backbone.stages\n",
    "            else: all_stages = backbone.blocks\n",
    "            num_total_blocks = len(all_stages)\n",
    "            if num_layers_to_unfreeze > num_total_blocks:\n",
    "                num_layers_to_unfreeze = num_total_blocks\n",
    "            stages_to_unfreeze = all_stages[-num_layers_to_unfreeze:]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model_type: {model_type}.\")\n",
    "\n",
    "    for stage in stages_to_unfreeze:\n",
    "        for param in stage.parameters():\n",
    "            \n",
    "    # 4. ì°¨ë“± í•™ìŠµë¥ ì„ ì ìš©í•  íŒŒë¼ë¯¸í„° ê·¸ë£¹ ìƒì„± í˜¹ì€ ë‹¨ì¼ ê·¸ë£¹ ìƒì„±\n",
    "    #    requires_grad=Trueì¸ íŒŒë¼ë¯¸í„°ë§Œ í•„í„°ë§í•˜ì—¬ ê° ê·¸ë£¹ì— í¬í•¨ì‹œí‚µë‹ˆë‹¤.\n",
    "    param_groups = []\n",
    "    if use_differential_lr:\n",
    "        param_groups = [\n",
    "            {\n",
    "                \"params\": filter(lambda p: p.requires_grad, model.backbone.parameters()),\n",
    "                \"lr\": backbone_lr\n",
    "            },\n",
    "            {\n",
    "                \"params\": filter(lambda p: p.requires_grad, model.neck.parameters()),\n",
    "                \"lr\": head_lr\n",
    "            },\n",
    "            {\n",
    "                \"params\": filter(lambda p: p.requires_grad, model.head.parameters()),\n",
    "                \"lr\": head_lr\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        print(f\"Unfrozen the last {num_layers_to_unfreeze} backbone layers, neck, and head for model type: {model_type}.\")\n",
    "        backbone_params = list(filter(lambda p: p.requires_grad, model.backbone.parameters()))\n",
    "        if backbone_params:\n",
    "            param_groups.append({\"params\": backbone_params, \"lr\": backbone_lr})\n",
    "\n",
    "        if hasattr(model, 'neck'):\n",
    "            neck_params = list(filter(lambda p: p.requires_grad, model.neck.parameters()))\n",
    "            if neck_params:\n",
    "                param_groups.append({\"params\": neck_params, \"lr\": head_lr})\n",
    "\n",
    "        if hasattr(model, 'head'):\n",
    "            head_params = list(filter(lambda p: p.requires_grad, model.head.parameters()))\n",
    "            if head_params:\n",
    "                param_groups.append({\"params\": head_params, \"lr\": head_lr})\n",
    "\n",
    "        print(f\"Unfrozen the last {num_layers_to_unfreeze} backbone layers, neck, and head.\")\n",
    "        print(f\"Applied differential learning rate: backbone_lr={backbone_lr}, head_lr={head_lr}\")\n",
    "    else:\n",
    "        # ë‹¨ì¼ í•™ìŠµë¥  ê·¸ë£¹ ìƒì„± (í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ìŒ)\n",
    "        param_groups = filter(lambda p: p.requires_grad, model.parameters())\n",
    "        print(\"Differential learning rate disabled. Using a single LR for all trainable parameters.\")\n",
    "        \n",
    "\n",
    "    return param_groups\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    save_path = f'{output_root}/checkpoint.pth'\n",
    "    \n",
    "    # load model\n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model: nn.Module = ModelClass(num_classes=num_classes).to(device)\n",
    "    \n",
    "    if cfg[\"use_unfreeze\"]:\n",
    "    # ì†ì‹¤ í•¨ìˆ˜\n",
    "    criterion = get_loss(cfg_loss[\"name\"], cfg_loss[\"params\"])\n",
    "\n",
    "    # --- 1ë‹¨ê³„: í—¤ë“œ í•™ìŠµ ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸš€ STARTING STAGE 1: HEAD TRAINING\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # í—¤ë“œë§Œ í•™ìŠµí•˜ë„ë¡ íŒŒë¼ë¯¸í„° ì„¤ì • (ë°±ë³¸ ë™ê²°)\n",
    "    head_params = setup_optimizer_params(\n",
    "        model=model,\n",
    "        model_type=cfg[\"model_type\"], \n",
    "        num_layers_to_unfreeze=0, # ë°±ë³¸ì€ ë™ê²°\n",
    "        backbone_lr=0, # ì˜ë¯¸ ì—†ìŒ\n",
    "        head_lr=cfg[\"head_only_lr\"], # í—¤ë“œ í•™ìŠµìš© LR\n",
    "        use_differential_lr=False # ëª¨ë“  í•™ìŠµ íŒŒë¼ë¯¸í„°ì— ë‹¨ì¼ LR ì ìš©\n",
    "    )\n",
    "\n",
    "    optimizer_head = get_optimizer(cfg_optimizer[\"name\"], head_params, {\"lr\": cfg[\"head_only_lr\"]})\n",
    "    scheduler_head = get_scheduler(cfg_scheduler[\"name\"], optimizer_head, cfg_scheduler['params'])\n",
    "    \n",
    "    # 1ë‹¨ê³„ í•™ìŠµ ì‹¤í–‰\n",
    "    training_loop(\n",
    "        training_fn, model, train_loader, val_loader, train_dataset, val_dataset, \n",
    "        criterion, optimizer_head, device, cfg[\"head_only_epochs\"], \n",
    "        None, logger, class_names, scheduler_head, {}\n",
    "    )\n",
    "\n",
    "    # --- 2ë‹¨ê³„: ì „ì²´ ë¯¸ì„¸ ì¡°ì • ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸš€ STARTING STAGE 2: FULL FINE-TUNING\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # ë°±ë³¸ ì¼ë¶€ì™€ í—¤ë“œë¥¼ í•¨ê»˜ í•™ìŠµí•˜ë„ë¡ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    if cfg[\"use_unfreeze\"]:\n",
    "        params_to_update = setup_optimizer_params(\n",
    "                                model=model,\n",
    "                                model_type=cfg[\"model_type\"], \n",
    "                                num_layers_to_unfreeze=cfg[\"num_blocks_to_unfreeze\"],\n",
    "                                backbone_lr=cfg[\"backbone_lr\"],\n",
    "                                head_lr=cfg_optimizer[\"params\"][\"lr\"],\n",
    "                                use_differential_lr=cfg[\"use_differential_lr\"]\n",
    "                            )\n",
    "            model=model,\n",
    "            model_type=cfg[\"model_type\"], \n",
    "            num_layers_to_unfreeze=cfg[\"num_blocks_to_unfreeze\"],\n",
    "            backbone_lr=cfg[\"backbone_lr\"],\n",
    "            head_lr=cfg_optimizer[\"params\"][\"lr\"],\n",
    "            use_differential_lr=cfg[\"use_differential_lr\"]\n",
    "        )\n",
    "    else:\n",
    "        params_to_update = model.parameters()\n",
    "\n",
    "    # 2ë‹¨ê³„ìš© ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬, EarlyStopping ì¬ì„¤ì •\n",
    "    save_path = f'{output_root}/{filename}_checkpoint.pth'\n",
    "    early_stopping = EarlyStopping(patience=cfg[\"patience\"], delta=cfg[\"delta\"], verbose=True, save_path=save_path, mode='max')\n",
    "\n",
    "    # ì†ì‹¤ í•¨ìˆ˜\n",
    "    criterion = get_loss(cfg_loss[\"name\"], cfg_loss[\"params\"])\n",
    "\n",
    "    # ì˜µí‹°ë§ˆì´ì €\n",
    "    optimizer = get_optimizer(cfg_optimizer[\"name\"], params_to_update, cfg_optimizer[\"params\"])\n",
    "\n",
    "    # ìŠ¤ì¼€ì¥´ëŸ¬\n",
    "    Scheduler = get_scheduler(cfg_scheduler[\"name\"], optimizer, cfg_scheduler['params'])\n",
    "    \n",
    "    # ampë¥¼ ìœ„í•œ scaler ì¤€ë¹„\n",
    "    scheduler = get_scheduler(cfg_scheduler[\"name\"], optimizer, cfg_scheduler['params'])\n",
    "    \n",
    "    training_args = {}\n",
    "    if cfg[\"training_mode\"] == 'on_amp':\n",
    "        training_args['scaler'] = GradScaler()\n",
    "\n",
    "    # 2ë‹¨ê³„ í•™ìŠµ ì‹¤í–‰\n",
    "    model, valid_max_accuracy = training_loop(\n",
    "        training_fn,\n",
    "        model, train_loader, val_loader, train_dataset, val_dataset, \n",
    "        criterion, optimizer, device, cfg[\"EPOCHS\"], \n",
    "        early_stopping, logger, class_names, Scheduler,\n",
    "        early_stopping, logger, class_names, scheduler,\n",
    "        training_args,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"\\nğŸ‰ Training Finished! Best validation accuracy: {valid_max_accuracy:.4f}\")\n",
    "\n",
    "âš™ï¸ ì„¤ì • íŒŒì¼(main_config.yaml) ì¶”ê°€ í•­ëª©\n",
    "ì´ ìƒˆë¡œìš´ í•™ìŠµ ì „ëµì„ ì‚¬ìš©í•˜ë ¤ë©´ config/main_config.yaml íŒŒì¼ì— 1ë‹¨ê³„ í•™ìŠµì„ ì œì–´í•˜ê¸° ìœ„í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "yaml\n",
    "# config/main_config.yaml\n",
    "\n",
    "# ... ê¸°ì¡´ ì„¤ì • ...\n",
    "\n",
    "# === ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹ ì„¤ì • ===\n",
    "head_only_epochs: 3       # 1ë‹¨ê³„(í—¤ë“œë§Œ) í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
    "head_only_lr: 0.001       # 1ë‹¨ê³„ í•™ìŠµ ì‹œ ì‚¬ìš©í•  í•™ìŠµë¥ \n",
    "\n",
    "# === ê¸°ì¡´ í•™ìŠµ ì„¤ì • (2ë‹¨ê³„ìš©) ===\n",
    "EPOCHS: 15                # 2ë‹¨ê³„(ì „ì²´) í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
    "use_unfreeze: True\n",
    "num_blocks_to_unfreeze: 4\n",
    "use_differential_lr: True\n",
    "backbone_lr: 0.00001\n",
    "\n",
    "optimizer:\n",
    "  name: \"AdamW\"\n",
    "  params:\n",
    "    lr: 0.0001            # 2ë‹¨ê³„ í•™ìŠµ ì‹œ í—¤ë“œì— ì ìš©ë  í•™ìŠµë¥ \n",
    "    weight_decay: 0.01\n",
    "\n",
    "# ... ë‚˜ë¨¸ì§€ ì„¤ì • ...\n",
    "ì´ì²˜ëŸ¼ í•™ìŠµ ê³¼ì •ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ê³  ê° ë‹¨ê³„ì— ë§ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì‹ ì¤‘í•˜ê²Œ ì„¤ì •í•˜ë©´, ëª¨ë¸ì˜ ì ì¬ë ¥ì„ ìµœëŒ€í•œìœ¼ë¡œ ì´ëŒì–´ë‚´ì–´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ìœ¼ì‹¤ ìˆ˜ ìˆì„ ê²ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed128aa",
   "metadata": {},
   "source": [
    "PyTorchì˜ OneCycleLR ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹ì— ì ìš©í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜.\n",
    "\n",
    "\n",
    "Gemini\n",
    "ì•ˆë…•í•˜ì„¸ìš”! OneCycleLR ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹ì— ì ìš©í•˜ëŠ” ê²ƒì€ ëª¨ë¸ì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ë†’ì´ê³  ìµœì¢… ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë° ë§¤ìš° íš¨ê³¼ì ì¸ ì „ëµì…ë‹ˆë‹¤.\n",
    "\n",
    "OneCycleLRì˜ í•µì‹¬ì€ ë§¤ ë°°ì¹˜(step)ë§ˆë‹¤ í•™ìŠµë¥ ì„ ì¡°ì ˆí•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ê¸°ì¡´ì˜ ì—í¬í¬(epoch)ë§ˆë‹¤ í•™ìŠµë¥ ì„ ì¡°ì ˆí•˜ë˜ ë°©ì‹ì—ì„œ ì•½ê°„ì˜ ì½”ë“œ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹ì— OneCycleLRì„ ì ìš©í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. config/main_config.yaml íŒŒì¼ ìˆ˜ì •\n",
    "ë¨¼ì € ì„¤ì • íŒŒì¼ì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ OneCycleLRë¡œ ë³€ê²½í•˜ê³ , ê´€ë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. max_lrê³¼ total_stepsëŠ” ì½”ë“œ ë‚´ì—ì„œ ë™ì ìœ¼ë¡œ ê³„ì‚°ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë§Œ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "main_config.yaml\n",
    "-6\n",
    "+9\n",
    "BATCH_SIZE: 16\n",
    "EPOCHS: 100\n",
    "EPOCHS: 15 # 2ë‹¨ê³„(ì „ì²´) í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
    "SEED: 42\n",
    "head_only_epochs: 3 # 1ë‹¨ê³„(í—¤ë“œë§Œ) í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
    "head_only_lr: 0.001 # 1ë‹¨ê³„ í•™ìŠµ ì‹œ ì‚¬ìš©í•  ìµœëŒ€ í•™ìŠµë¥ \n",
    "\n",
    "use_unfreeze: True\n",
    "num_blocks_to_unfreeze: 4 # ëª¨ë¸ì˜ í”¼ì²˜ ë¶€ë¶„ì„ ì–¼ë§ˆë‚˜ ë” í•™ìŠµì‹œí‚¬ ê²ƒì¸ì§€\n",
    "model_type: resnet # efficientnet, resnet, convnext, swin\n",
    "  }\n",
    "\n",
    "scheduler:\n",
    "  name: cosine_warm_restart\n",
    "  name: OneCycleLR # ìŠ¤ì¼€ì¤„ëŸ¬ ë³€ê²½\n",
    "  params: {\n",
    "        T_0: 20,\n",
    "        T_mult: 1,\n",
    "        eta_min: 0.0000001,\n",
    "    }\n",
    "    pct_start: 0.3, # ì „ì²´ ìŠ¤í… ì¤‘ í•™ìŠµë¥ ì´ ì˜¬ë¼ê°€ëŠ” êµ¬ê°„ì˜ ë¹„ìœ¨\n",
    "    div_factor: 25, # ì´ˆê¸° í•™ìŠµë¥  = max_lr / div_factor\n",
    "    final_div_factor: 1.0e+4, # ë§ˆì§€ë§‰ í•™ìŠµë¥  = ì´ˆê¸° í•™ìŠµë¥  / final_div_factor\n",
    "  }\n",
    "\n",
    "loss:\n",
    "  name: FocalLoss\n",
    "\n",
    "2. utils/scheduler_factory.py íŒŒì¼ ìˆ˜ì •\n",
    "get_scheduler í•¨ìˆ˜ê°€ OneCycleLRì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "(í•´ë‹¹ íŒŒì¼ì´ ì œê³µë˜ì§€ ì•Šì•„, ì¼ë°˜ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì •í•˜ì—¬ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ì½”ë“œì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.)\n",
    "\n",
    "scheduler_factory.py\n",
    "-0\n",
    "+11\n",
    "The code change produced by Gemini cannot be automatically applied. You can manually apply the change or ask Gemini to try again.\n",
    "from typing import Iterable\n",
    "\n",
    "from torch.optim import Adam, AdamW, SGD\n",
    "from torch import optim\n",
    "from torch.nn import Module, Parameter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR\n",
    "\n",
    "\n",
    "OPTIMIZER_REGISTRY: dict[str, optim.Optimizer] = {\n",
    "    \"Adam\": Adam,\n",
    "    \"AdamW\": AdamW,\n",
    "    \"SGD\": SGD,\n",
    "}\n",
    "SCHEDULER_REGISTRY: dict[str, optim.lr_scheduler._LRScheduler] = {\n",
    "    \"cosine_warm_restart\": CosineAnnealingWarmRestarts,\n",
    "    \"OneCycleLR\": OneCycleLR,\n",
    "}\n",
    "\n",
    "def get_optimizer(name: str, params_to_update: Iterable[Parameter], params: dict) -> optim.Optimizer:\n",
    "        raise ValueError(f\"Unknown optimizer: {name}\")\n",
    "    return OPTIMIZER_REGISTRY[name](params_to_update, **params)\n",
    "\n",
    "def get_scheduler(name: str, optimizer: optim.Optimizer, params: dict) -> optim.lr_scheduler._LRScheduler:\n",
    "    if name not in SCHEDULER_REGISTRY:\n",
    "        raise ValueError(f\"Unknown scheduler: {name}\")\n",
    "    # OneCycleLRì€ epochë§ˆë‹¤ stepí•˜ëŠ” ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ë‹¬ë¦¬, ë§¤ stepë§ˆë‹¤ í˜¸ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    # trainer.pyì˜ training_loop ë‚´ì—ì„œ scheduler.step()ì´ ë°°ì¹˜(batch)ë§ˆë‹¤ í˜¸ì¶œë˜ë„ë¡ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    return SCHEDULER_REGISTRY[name](optimizer, **params)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torch import nn\n",
    "\n",
    "3. main.py íŒŒì¼ ìˆ˜ì •\n",
    "ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ê° í•™ìŠµ ë‹¨ê³„ì— ë§ê²Œ OneCycleLR ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "1ë‹¨ê³„: head_only_lrì„ max_lrë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "2ë‹¨ê³„: ì°¨ë“± í•™ìŠµë¥ ì„ ìœ„í•´ max_lrì„ ë¦¬ìŠ¤íŠ¸([backbone_lr, head_lr, ...]) í˜•íƒœë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "main.py\n",
    "-3\n",
    "+16\n",
    "        use_differential_lr=False # ëª¨ë“  í•™ìŠµ íŒŒë¼ë¯¸í„°ì— ë‹¨ì¼ LR ì ìš©\n",
    "    )\n",
    "\n",
    "    # 1ë‹¨ê³„ìš© OneCycleLR ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "    scheduler_params_stage1 = cfg_scheduler[\"params\"].copy()\n",
    "    scheduler_params_stage1['max_lr'] = cfg[\"head_only_lr\"]\n",
    "    scheduler_params_stage1['total_steps'] = len(train_loader) * cfg[\"head_only_epochs\"]\n",
    "    if scheduler_params_stage1['total_steps'] == 0: scheduler_params_stage1['total_steps'] = 1 # epochs=0ì¼ë•Œ ì—ëŸ¬ ë°©ì§€\n",
    "\n",
    "    optimizer_head = get_optimizer(cfg_optimizer[\"name\"], head_params, {\"lr\": cfg[\"head_only_lr\"]})\n",
    "    scheduler_head = get_scheduler(cfg_scheduler[\"name\"], optimizer_head, cfg_scheduler['params'])\n",
    "    scheduler_head = get_scheduler(cfg_scheduler[\"name\"], optimizer_head, scheduler_params_stage1)\n",
    "    \n",
    "    # 1ë‹¨ê³„ í•™ìŠµ ì‹¤í–‰\n",
    "    training_loop(\n",
    "        training_fn, model, train_loader, val_loader, train_dataset, val_dataset, \n",
    "        criterion, optimizer_head, device, cfg[\"head_only_epochs\"], \n",
    "        criterion, optimizer_head, device, cfg[\"head_only_epochs\"],\n",
    "        None, logger, class_names, scheduler_head, {}\n",
    "    )\n",
    "\n",
    "\n",
    "    # 2ë‹¨ê³„ìš© ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬, EarlyStopping ì¬ì„¤ì •\n",
    "    save_path = f'{output_root}/{filename}_checkpoint.pth'\n",
    "    early_stopping = EarlyStopping(patience=cfg[\"patience\"], delta=cfg[\"delta\"], verbose=True, save_path=save_path, mode='max')\n",
    "    optimizer = get_optimizer(cfg_optimizer[\"name\"], params_to_update, cfg_optimizer[\"params\"])\n",
    "    scheduler = get_scheduler(cfg_scheduler[\"name\"], optimizer, cfg_scheduler['params'])\n",
    "    \n",
    "    # 2ë‹¨ê³„ìš© OneCycleLR ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "    scheduler_params_stage2 = cfg_scheduler[\"params\"].copy()\n",
    "    # ì°¨ë“± í•™ìŠµë¥ ì„ ìœ„í•´ max_lrì„ ë¦¬ìŠ¤íŠ¸ë¡œ êµ¬ì„±\n",
    "    max_lrs = [pg.get('lr', cfg_optimizer['params']['lr']) for pg in optimizer.param_groups]\n",
    "    scheduler_params_stage2['max_lr'] = max_lrs\n",
    "    scheduler_params_stage2['total_steps'] = len(train_loader) * cfg[\"EPOCHS\"]\n",
    "    scheduler = get_scheduler(cfg_scheduler[\"name\"], optimizer, scheduler_params_stage2)\n",
    "\n",
    "    training_args = {}\n",
    "    if cfg[\"training_mode\"] == 'on_amp':\n",
    "        training_args['scaler'] = GradScaler()\n",
    "\n",
    "4. trainer ëª¨ë“ˆ ìˆ˜ì • (ê°€ì¥ ì¤‘ìš”)\n",
    "OneCycleLRì€ ë§¤ ë°°ì¹˜(step)ë§ˆë‹¤ scheduler.step()ì„ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ training_loopëŠ” ì—í¬í¬(epoch)ê°€ ëë‚  ë•Œ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì—…ë°ì´íŠ¸í•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. training_loop í•¨ìˆ˜ ë‚´ë¶€ì˜ í•™ìŠµ ë£¨í”„ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "(íŒŒì¼ì´ ì œê³µë˜ì§€ ì•Šì•„, trainer/trainer.pyì— training_loopê°€ ìˆë‹¤ê³  ê°€ì •í•˜ê³  ìˆ˜ì •ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.)\n",
    "\n",
    "trainer.py\n",
    "-5\n",
    "+10\n",
    "The code change produced by Gemini cannot be automatically applied. You can manually apply the change or ask Gemini to try again.\n",
    "# ì´ íŒŒì¼ì€ ê°€ìƒì˜ trainer/trainer.py ì…ë‹ˆë‹¤. ì‹¤ì œ íŒŒì¼ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def training_loop(\n",
    "    training_fn,\n",
    "            # ... (ê¸°ì¡´ í•™ìŠµ ì½”ë“œ: loss ê³„ì‚°, backpropagation ë“±)\n",
    "            optimizer.step()\n",
    "\n",
    "            # âš ï¸ ì¤‘ìš”: OneCycleLRì„ ìœ„í•´ ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸ë¥¼ ë°°ì¹˜ ë£¨í”„ ì•ˆìœ¼ë¡œ ì´ë™\n",
    "            if scheduler is not None:\n",
    "                # OneCycleLRì€ ë°°ì¹˜ë§ˆë‹¤ stepì„ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "                if isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step()\n",
    "\n",
    "        # --- Epoch ì¢…ë£Œ ---\n",
    "        # âš ï¸ ê¸°ì¡´ ì½”ë“œì—ì„œëŠ” ì—¬ê¸°ì— ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸ê°€ ìˆì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        # if scheduler is not None:\n",
    "        #     scheduler.step()\n",
    "\n",
    "        # ... (ê¸°ì¡´ ê²€ì¦ ë£¨í”„ ë° ë¡œê¹… ì½”ë“œ)\n",
    "        # OneCycleLRì´ ì•„ë‹Œ ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬(ì˜ˆ: CosineAnnealing)ë¥¼ ìœ„í•œ ë¡œì§\n",
    "        if scheduler is not None and not isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n",
    "            scheduler.step()\n",
    "\n",
    "    # ... (ë‚˜ë¨¸ì§€ ì½”ë“œ)\n",
    "    return model, best_score\n",
    "\n",
    "í•µì‹¬ ë³€ê²½ ì‚¬í•­:\n",
    "\n",
    "scheduler.step() í˜¸ì¶œì„ ì—í¬í¬ ë£¨í”„ì˜ ëì—ì„œ ë°°ì¹˜(í•™ìŠµ) ë£¨í”„ì˜ ëìœ¼ë¡œ ì´ë™ì‹œì¼°ìŠµë‹ˆë‹¤.\n",
    "isinstanceë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ OneCycleLRì¼ ë•Œë§Œ ë°°ì¹˜ë§ˆë‹¤ ì—…ë°ì´íŠ¸í•˜ê³ , ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ê¸°ì¡´ì²˜ëŸ¼ ì—í¬í¬ë§ˆë‹¤ ì—…ë°ì´íŠ¸í•˜ë„ë¡ í•˜ì—¬ í˜¸í™˜ì„±ì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤.\n",
    "ì´ ë³€ê²½ ì‚¬í•­ë“¤ì„ ì ìš©í•˜ë©´, ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹ì˜ ê° ë‹¨ê³„ì—ì„œ OneCycleLR ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ìµœì ì˜ í•™ìŠµë¥ ì„ ì°¾ì•„ë‚´ì–´ ë” ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec7077",
   "metadata": {},
   "source": [
    "ê·¸ë¦¬ê³  ë„ˆê°€ ë§í•´ì¤¬ë˜ K-Fold êµì°¨ ê²€ì¦ê³¼ ì•™ìƒë¸”ì˜ ê²°í•© ì´ê²ƒë„ í•œë²ˆ ì ìš©ì‹œì¼œì¤¬ìœ¼ë©´ ì¢‹ê² ì–´\n",
    "\n",
    "\n",
    "Gemini\n",
    "ë¬¼ë¡ ì…ë‹ˆë‹¤! K-Fold êµì°¨ ê²€ì¦ê³¼ ì•™ìƒë¸”ì„ ê²°í•©í•˜ëŠ” ê²ƒì€ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë§¤ìš° ê°•ë ¥í•œ ì „ëµì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ main_test.pyì™€ inference_ensemble.pyë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê³ , ì „ì²´ ê³¼ì •ì„ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš°: run_kfold_ensemble.py\n",
    "ì´ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì˜ í•µì‹¬ì€ í•˜ë‚˜ì˜ ìŠ¤í¬ë¦½íŠ¸ì™€ í•˜ë‚˜ì˜ ì„¤ì • íŒŒì¼ë¡œ ì „ì²´ ê³¼ì •ì„ ì œì–´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì¤‘ì•™ ì„¤ì • íŒŒì¼ (kfold_ensemble_config.yaml): ì–´ë–¤ ëª¨ë¸ë“¤ì„, ëª‡ ê°œì˜ Foldë¡œ, ì–´ë–¤ ê°€ì¤‘ì¹˜ë¡œ ì•™ìƒë¸”í• ì§€ ëª¨ë“  ê²ƒì„ ì—¬ê¸°ì„œ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (run_kfold_ensemble.py): ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‘ ê°€ì§€ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.\n",
    "train ëª¨ë“œ: ì„¤ì • íŒŒì¼ì— ì •ì˜ëœ ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ K-Fold êµì°¨ ê²€ì¦ í•™ìŠµì„ ì‹¤í–‰í•˜ê³ , ê° Foldì˜ ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ì²´í¬í¬ì¸íŠ¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤. (ì˜ˆ: 3ê°œ ëª¨ë¸, 5-Fold -> 15ê°œ ì²´í¬í¬ì¸íŠ¸ ìƒì„±)\n",
    "inference ëª¨ë“œ: train ëª¨ë“œì—ì„œ ìƒì„±ëœ ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” ë° TTA(Test Time Augmentation)ë¥¼ ì ìš©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "1. ìŠ¤ì¼€ì¤„ëŸ¬ íŒ©í† ë¦¬ ìˆ˜ì •\n",
    "ë¨¼ì €, OneCycleLR ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ utils/scheduler_factory.pyì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "scheduler_factory.py\n",
    "-1\n",
    "+2\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts, OneCycleLR\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "SCHEDULER_REGISTRY: dict[str, type] = {\n",
    "    \"step\": StepLR,\n",
    "    \"multistep\": MultiStepLR,\n",
    "    \"cosine\": CosineAnnealingLR,\n",
    "    \"plateau\": ReduceLROnPlateau,\n",
    "    \"cosine_warm_restart\": CosineAnnealingWarmRestarts,\n",
    "    \"OneCycleLR\": OneCycleLR,\n",
    "}\n",
    "\n",
    "def get_scheduler(name: str, optimizer: optim.Optimizer, params: dict) -> optim.lr_scheduler._LRScheduler:\n",
    "\n",
    "2. ìƒˆë¡œìš´ ì¤‘ì•™ ì„¤ì • íŒŒì¼ ìƒì„±\n",
    "í”„ë¡œì íŠ¸ì˜ ë£¨íŠ¸ config í´ë”ì— ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ kfold_ensemble_config.yaml íŒŒì¼ì„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤. ì´ íŒŒì¼ì´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì˜ \"ì¡°ì¢…ì„\" ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "New file: kfold_ensemble_config.yaml\n",
    "+34\n",
    "# Global settings for K-Fold and Ensemble\n",
    "SEED: 42\n",
    "N_SPLITS: 5 # K-Foldì˜ K ê°’\n",
    "DATA_PATH: './data'\n",
    "OUTPUT_ROOT: './output'\n",
    "NUM_CLASSES: 17\n",
    "\n",
    "# ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\n",
    "# ê° ëª¨ë¸ì€ ê³ ìœ í•œ í•™ìŠµ ì„¤ì •(config_path)ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "MODELS:\n",
    "  - # ëª¨ë¸ A: ResNeSt\n",
    "    config_path: \"config/main_config.yaml\" # ì´ ëª¨ë¸ì— ëŒ€í•œ í•™ìŠµ ì„¤ì • íŒŒì¼\n",
    "    weight: 0.4 # ì•™ìƒë¸” ê°€ì¤‘ì¹˜\n",
    "\n",
    "  - # ëª¨ë¸ B: EfficientNet (ê°€ì •)\n",
    "    # main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL ì´ë¦„ë§Œ ë°”ê¿”ì„œ ì‚¬ìš© ê°€ëŠ¥\n",
    "    config_path: \"config/effnet_config.yaml\"\n",
    "    weight: 0.3\n",
    "\n",
    "  - # ëª¨ë¸ C: ConvNeXt (ê°€ì •)\n",
    "    # main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL ì´ë¦„ë§Œ ë°”ê¿”ì„œ ì‚¬ìš© ê°€ëŠ¥\n",
    "    config_path: \"config/convnext_config.yaml\"\n",
    "    weight: 0.3\n",
    "\n",
    "# ì¶”ë¡  ì‹œ ì„¤ì •\n",
    "INFERENCE:\n",
    "  batch_size: 16\n",
    "  use_tta: True\n",
    "  # TTAì— ì‚¬ìš©í•  ë³€í™˜ ë¦¬ìŠ¤íŠ¸ (torchvision.transforms í˜•ì‹)\n",
    "  tta_transforms:\n",
    "    - name: \"RandomHorizontalFlip\"\n",
    "      params: { p: 1.0 }\n",
    "    - name: \"RandomAffine\"\n",
    "      params: { degrees: 10,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b3254",
   "metadata": {},
   "source": [
    "ì§€ê¸ˆ ë„ˆê°€ ê°œì„ í•´ì¤€ë¶€ë¶„ ì „ë¶€ ë³€ê²½í–ˆëŠ”ë° ì´ëŸ¬ë©´ ì–´ë–¤ pyíŒŒì¼ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•´ì•¼í• ê¹Œ?\n",
    "\n",
    "\n",
    "Gemini\n",
    "ë„¤, ê·¸ëŸ¼ìš”! ì§€ê¸ˆê¹Œì§€ ì œì•ˆí•´ ë“œë¦° ëª¨ë“  ê°œì„  ì‚¬í•­(ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹, K-Fold, ì•™ìƒë¸”)ì„ í†µí•©í•˜ì—¬, ì´ì œ ì–´ë–¤ íŒŒì¼ì„ ì–´ë–»ê²Œ ì‹¤í–‰í•´ì•¼ í•˜ëŠ”ì§€ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê°€ì¥ í° ë³€í™”ëŠ” ì—¬ëŸ¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë”°ë¡œ ì‹¤í–‰í•  í•„ìš” ì—†ì´, ë‹¨ í•˜ë‚˜ì˜ í†µí•© ìŠ¤í¬ë¦½íŠ¸(run_kfold_ensemble.py)ë¡œ ì „ì²´ í•™ìŠµê³¼ ì¶”ë¡  ê³¼ì •ì„ ê´€ë¦¬í•˜ê²Œ ë˜ì—ˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ìƒˆë¡œìš´ ì‹¤í–‰ ìˆœì„œ ìš”ì•½\n",
    "ì´ì œ ë³µì¡í•œ ê³¼ì •ì€ ìŠìœ¼ì…”ë„ ë©ë‹ˆë‹¤. ì‹¤í–‰ ìˆœì„œëŠ” ì•„ë˜ì™€ ê°™ì´ ë§¤ìš° ê°„ë‹¨í•´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "(ì„ íƒ ì‚¬í•­) í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬: test_data_preprocess.pyë¥¼ ì‹¤í–‰í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ë¯¸ë¦¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "í•™ìŠµ ì‹¤í–‰: run_kfold_ensemble.pyë¥¼ train ëª¨ë“œë¡œ ì‹¤í–‰í•˜ì—¬ ì„¤ì • íŒŒì¼ì— ì •ì˜ëœ ëª¨ë“  ëª¨ë¸ì„ K-Foldë¡œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "ì¶”ë¡  ì‹¤í–‰: run_kfold_ensemble.pyë¥¼ inference ëª¨ë“œë¡œ ì‹¤í–‰í•˜ì—¬ í•™ìŠµëœ ëª¨ë“  ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ ì•™ìƒë¸” ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ìµœì¢… ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "âš™ï¸ 1ë‹¨ê³„: kfold_ensemble_config.yaml ì„¤ì •í•˜ê¸°\n",
    "ë¨¼ì €, í”„ë¡œì íŠ¸ì˜ \"ì¡°ì¢…ì„\" ì—­í• ì„ í•  ì„¤ì • íŒŒì¼ì„ ì™„ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ íŒŒì¼ í•˜ë‚˜ë¡œ ì–´ë–¤ ëª¨ë¸ì„, ëª‡ Foldë¡œ, ì–´ë–»ê²Œ ì•™ìƒë¸”í• ì§€ ëª¨ë‘ ì œì–´í•©ë‹ˆë‹¤.\n",
    "\n",
    "config/kfold_ensemble_config.yaml íŒŒì¼ì„ ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ ìƒì„±í•˜ê±°ë‚˜ ìˆ˜ì •í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "kfold_ensemble_config.yaml\n",
    "-12\n",
    "+18\n",
    "# Global settings for K-Fold and Ensemble\n",
    "SEED: 42\n",
    "N_SPLITS: 5 # K-Foldì˜ K ê°’\n",
    "DATA_PATH: './data'\n",
    "DATA_ROOT: './data'\n",
    "OUTPUT_ROOT: './output'\n",
    "NUM_CLASSES: 17\n",
    "\n",
    "# ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\n",
    "# ê° ëª¨ë¸ì€ ê³ ìœ í•œ í•™ìŠµ ì„¤ì •(config_path)ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "MODELS:\n",
    "  - # ëª¨ë¸ A: ResNeSt\n",
    "  - # --- ëª¨ë¸ A: ResNeSt101e ---\n",
    "    model_name: \"ResNeSt101e\" # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ëª…ì— ì‚¬ìš©ë  ê³ ìœ  ì´ë¦„\n",
    "    config_path: \"config/main_config.yaml\" # ì´ ëª¨ë¸ì— ëŒ€í•œ í•™ìŠµ ì„¤ì • íŒŒì¼\n",
    "    weight: 0.4 # ì•™ìƒë¸” ê°€ì¤‘ì¹˜\n",
    "\n",
    "  - # ëª¨ë¸ B: EfficientNet (ê°€ì •)\n",
    "    # main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL ì´ë¦„ë§Œ ë°”ê¿”ì„œ ì‚¬ìš© ê°€ëŠ¥\n",
    "    config_path: \"config/effnet_config.yaml\"\n",
    "  - # --- ëª¨ë¸ B: EfficientNetV2 (ê°€ì •) ---\n",
    "    model_name: \"EfficientNetV2\"\n",
    "    # main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL, model_type ë“±ë§Œ ë°”ê¿”ì„œ ì‚¬ìš©\n",
    "    config_path: \"config/effnet_config.yaml\" # ì˜ˆì‹œ íŒŒì¼ëª…\n",
    "    weight: 0.3\n",
    "\n",
    "  - # ëª¨ë¸ C: ConvNeXt (ê°€ì •)\n",
    "    # main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL ì´ë¦„ë§Œ ë°”ê¿”ì„œ ì‚¬ìš© ê°€ëŠ¥\n",
    "    config_path: \"config/convnext_config.yaml\"\n",
    "  - # --- ëª¨ë¸ C: ConvNeXt (ê°€ì •) ---\n",
    "    model_name: \"ConvNeXt\"\n",
    "    # main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL, model_type ë“±ë§Œ ë°”ê¿”ì„œ ì‚¬ìš©\n",
    "    config_path: \"config/convnext_config.yaml\" # ì˜ˆì‹œ íŒŒì¼ëª…\n",
    "    weight: 0.3\n",
    "\n",
    "# ì¶”ë¡  ì‹œ ì„¤ì •\n",
    "INFERENCE:\n",
    "  batch_size: 16\n",
    "  use_tta: True\n",
    "  submission_filename: \"submission_ensemble.csv\"\n",
    "  # TTAì— ì‚¬ìš©í•  ë³€í™˜ ë¦¬ìŠ¤íŠ¸ (torchvision.transforms í˜•ì‹)\n",
    "  tta_transforms:\n",
    "    - name: \"RandomHorizontalFlip\"\n",
    "      params: { p: 1.0 }\n",
    "    - name: \"RandomAffine\"\n",
    "      params: { degrees: 10,\n",
    "    - name: \"HorizontalFlip\"\n",
    "      params: { p: 1.0 } # torchvision.transforms.v2\n",
    "    - name: \"RandomRotation\"\n",
    "      params: { degrees: 15 }\n",
    "    - name: \"RandomRotation\"\n",
    "      params: { degrees: -15 }\n",
    "\n",
    "ì¤‘ìš”: MODELS ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê° ëª¨ë¸ì˜ config_path (ì˜ˆ: config/effnet_config.yaml)ëŠ” ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì´ì–´ì•¼ í•©ë‹ˆë‹¤. main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL, model_type ë“±ë§Œ ìˆ˜ì •í•´ì„œ ì—¬ëŸ¬ ê°œë¥¼ ë§Œë“¤ì–´ë‘ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ–¥ï¸ 2ë‹¨ê³„: í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ run_kfold_ensemble.py ìƒì„±\n",
    "ê¸°ì¡´ì˜ main.py, main_test.py, inference_ensemble.pyì˜ í•µì‹¬ ê¸°ëŠ¥ë“¤ì„ ëª¨ë‘ í•©ì¹œ í†µí•© ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ run_kfold_ensemble.py íŒŒì¼ì„ ìƒˆë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "New file: run_kfold_ensemble.py\n",
    "+309\n",
    "The code change produced by Gemini cannot be automatically applied. You can manually apply the change or ask Gemini to try again.\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import argparse\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config.config import load_config\n",
    "from utils.utils import *\n",
    "from datasets.transforms import build_unified_transforms, build_tta_transforms\n",
    "\n",
    "from datasets import get_dataset\n",
    "from models import get_model\n",
    "\n",
    "from utils.EarlyStopping import EarlyStopping\n",
    "from utils.scheduler_factory import get_scheduler\n",
    "from utils.optimizer_factory import get_optimizer\n",
    "from utils.loss_factory import get_loss\n",
    "from trainer import *\n",
    "from trainer.wandb_logger import WandbLogger\n",
    "from utils.predict_tta import get_tta_predictions\n",
    "\n",
    "# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (main.pyì—ì„œ ê°€ì ¸ì˜´) ---\n",
    "\n",
    "def setup_optimizer_params(model: nn.Module, model_type: str, num_layers_to_unfreeze: int, backbone_lr: float, head_lr: float, use_differential_lr: bool):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model_type_lower = model_type.lower()\n",
    "    backbone = model.backbone\n",
    "    \n",
    "    stages_to_unfreeze = []\n",
    "    if num_layers_to_unfreeze > 0:\n",
    "        if model_type_lower.startswith('resnet'):\n",
    "            all_stages = [backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4]\n",
    "        elif model_type_lower.startswith('swin'): all_stages = backbone.layers\n",
    "        elif model_type_lower.startswith('convnext'): all_stages = backbone.stages\n",
    "        else: all_stages = backbone.blocks # efficientnet\n",
    "        \n",
    "        if num_layers_to_unfreeze > len(all_stages): num_layers_to_unfreeze = len(all_stages)\n",
    "        stages_to_unfreeze = all_stages[-num_layers_to_unfreeze:]\n",
    "\n",
    "    for stage in stages_to_unfreeze:\n",
    "        for param in stage.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if hasattr(model, 'neck'):\n",
    "        for param in model.neck.parameters(): param.requires_grad = True\n",
    "    if hasattr(model, 'head'):\n",
    "        for param in model.head.parameters(): param.requires_grad = True\n",
    "            \n",
    "    param_groups = []\n",
    "    if use_differential_lr:\n",
    "        backbone_params = list(filter(lambda p: p.requires_grad, model.backbone.parameters()))\n",
    "        if backbone_params: param_groups.append({\"params\": backbone_params, \"lr\": backbone_lr})\n",
    "\n",
    "        if hasattr(model, 'neck'):\n",
    "            neck_params = list(filter(lambda p: p.requires_grad, model.neck.parameters()))\n",
    "            if neck_params: param_groups.append({\"params\": neck_params, \"lr\": head_lr})\n",
    "\n",
    "        if hasattr(model, 'head'):\n",
    "            head_params = list(filter(lambda p: p.requires_grad, model.head.parameters()))\n",
    "            if head_params: param_groups.append({\"params\": head_params, \"lr\": head_lr})\n",
    "    else:\n",
    "        param_groups = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "    return param_groups\n",
    "\n",
    "# --- í•™ìŠµ íŒŒì´í”„ë¼ì¸ ---\n",
    "\n",
    "def run_fold_training(\n",
    "    fold: int,\n",
    "    model_config: dict,\n",
    "    global_config: dict,\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    device: torch.device\n",
    "):\n",
    "    # --- ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
    "    cfg = load_config(model_config['config_path'])\n",
    "    model_name = model_config['model_name']\n",
    "    \n",
    "    print(f\"\\n===== FOLD {fold+1}/{global_config['N_SPLITS']} | MODEL: {model_name} | CONFIG: {model_config['config_path']} =====\")\n",
    "    \n",
    "    set_seed(global_config['SEED'] + fold) # Foldë§ˆë‹¤ ë‹¤ë¥¸ ì‹œë“œ ì ìš©\n",
    "\n",
    "    # --- ë°ì´í„°ì…‹ ë° ë¡œë” ---\n",
    "    train_transform, val_transform = build_unified_transforms(cfg[\"transforms\"][\"train\"]), build_unified_transforms(cfg[\"transforms\"][\"val\"])\n",
    "    DatasetClass = get_dataset(cfg['DATASET'])\n",
    "    train_dataset = DatasetClass(df=train_df, data_root=f\"{global_config['DATA_ROOT']}/train/\", transform=train_transform)\n",
    "    val_dataset = DatasetClass(df=val_df, data_root=f\"{global_config['DATA_ROOT']}/train/\", transform=val_transform)\n",
    "    \n",
    "    sampler = setting_sampler(train_df)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg[\"BATCH_SIZE\"], sampler=sampler, num_workers=os.cpu_count()//2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg[\"BATCH_SIZE\"], shuffle=False, num_workers=os.cpu_count()//2, pin_memory=True)\n",
    "\n",
    "    # --- ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ë¡œê±° ---\n",
    "    ModelClass = get_model(cfg['MODEL'])\n",
    "    model = ModelClass(num_classes=global_config['NUM_CLASSES']).to(device)\n",
    "    criterion = get_loss(cfg[\"loss\"][\"name\"], cfg[\"loss\"][\"params\"])\n",
    "    \n",
    "    date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    run_name = f\"{model_name}_fold{fold+1}_{date}\"\n",
    "    save_path = f\"{global_config['OUTPUT_ROOT']}/{run_name}_checkpoint.pth\"\n",
    "    \n",
    "    logger = WandbLogger(\n",
    "        project_name=\"DTC-KFold-Ensemble\",\n",
    "        run_name=run_name,\n",
    "        config=cfg,\n",
    "        save_path=save_path\n",
    "    )\n",
    "\n",
    "    # --- 1ë‹¨ê³„: í—¤ë“œ í•™ìŠµ ---\n",
    "    print(\"\\n--- STAGE 1: HEAD TRAINING ---\")\n",
    "    if cfg['head_only_epochs'] > 0:\n",
    "        head_params = setup_optimizer_params(model, cfg[\"model_type\"], 0, 0, cfg[\"head_only_lr\"], False)\n",
    "        optimizer_head = get_optimizer(cfg[\"optimizer\"][\"name\"], head_params, {\"lr\": cfg[\"head_only_lr\"]})\n",
    "        \n",
    "        scheduler_params_s1 = cfg[\"scheduler\"][\"params\"].copy()\n",
    "        scheduler_params_s1['max_lr'] = cfg[\"head_only_lr\"]\n",
    "        scheduler_params_s1['total_steps'] = len(train_loader) * cfg[\"head_only_epochs\"]\n",
    "        scheduler_head = get_scheduler(cfg[\"scheduler\"][\"name\"], optimizer_head, scheduler_params_s1)\n",
    "        \n",
    "        training_loop(\n",
    "            TRAINING_REGISTRY[cfg['training_mode']], model, train_loader, val_loader, train_dataset, val_dataset, \n",
    "            criterion, optimizer_head, device, cfg[\"head_only_epochs\"], None, logger, None, scheduler_head, {}\n",
    "        )\n",
    "\n",
    "    # --- 2ë‹¨ê³„: ì „ì²´ ë¯¸ì„¸ ì¡°ì • ---\n",
    "    print(\"\\n--- STAGE 2: FULL FINE-TUNING ---\")\n",
    "    params_to_update = setup_optimizer_params(\n",
    "        model, cfg[\"model_type\"], cfg[\"num_blocks_to_unfreeze\"],\n",
    "        cfg[\"backbone_lr\"], cfg[\"optimizer\"][\"params\"][\"lr\"], cfg[\"use_differential_lr\"]\n",
    "    )\n",
    "    optimizer = get_optimizer(cfg[\"optimizer\"][\"name\"], params_to_update, cfg[\"optimizer\"][\"params\"])\n",
    "    \n",
    "    scheduler_params_s2 = cfg[\"scheduler\"][\"params\"].copy()\n",
    "    max_lrs = [pg.get('lr', cfg['optimizer']['params']['lr']) for pg in optimizer.param_groups]\n",
    "    scheduler_params_s2['max_lr'] = max_lrs\n",
    "    scheduler_params_s2['total_steps'] = len(train_loader) * cfg[\"EPOCHS\"]\n",
    "    scheduler = get_scheduler(cfg[\"scheduler\"][\"name\"], optimizer, scheduler_params_s2)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=cfg[\"patience\"], delta=cfg[\"delta\"], verbose=True, save_path=save_path, mode='max')\n",
    "    training_args = {'scaler': GradScaler()} if cfg[\"training_mode\"] == 'on_amp' else {}\n",
    "\n",
    "    training_loop(\n",
    "        TRAINING_REGISTRY[cfg['training_mode']], model, train_loader, val_loader, train_dataset, val_dataset, \n",
    "        criterion, optimizer, device, cfg[\"EPOCHS\"], early_stopping, logger, None, scheduler, training_args\n",
    "    )\n",
    "\n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del model, optimizer, scheduler, train_loader, val_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def train_pipeline(global_config):\n",
    "    print(\"ğŸš€ STARTING K-FOLD TRAINING PIPELINE ğŸš€\")\n",
    "    \n",
    "    # ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\n",
    "    full_train_df = pd.read_csv(f\"{global_config['DATA_ROOT']}/train_valid_set/train-label-fix-v1.csv\")\n",
    "    \n",
    "    # K-Fold ë¶„í• ê¸° ì„¤ì •\n",
    "    skf = StratifiedKFold(n_splits=global_config['N_SPLITS'], shuffle=True, random_state=global_config['SEED'])\n",
    "\n",
    "    for model_cfg in global_config['MODELS']:\n",
    "        # K-Fold ë£¨í”„ ì‹¤í–‰\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, full_train_df['target'])):\n",
    "            train_df = full_train_df.iloc[train_idx]\n",
    "            val_df = full_train_df.iloc[val_idx]\n",
    "            \n",
    "            run_fold_training(\n",
    "                fold=fold,\n",
    "                model_config=model_cfg,\n",
    "                global_config=global_config,\n",
    "                train_df=train_df,\n",
    "                val_df=val_df,\n",
    "                device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            )\n",
    "    print(\"\\nğŸ‰ ALL K-FOLD TRAINING FINISHED! ğŸ‰\")\n",
    "\n",
    "\n",
    "# --- ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ---\n",
    "\n",
    "def inference_pipeline(global_config):\n",
    "    print(\"ğŸš€ STARTING ENSEMBLE INFERENCE PIPELINE ğŸš€\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # --- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ ---\n",
    "    # test_data_preprocess.pyë¥¼ ì‹¤í–‰í–ˆë‹¤ë©´ test_modify í´ë” ì‚¬ìš©\n",
    "    test_dir = f\"{global_config['DATA_ROOT']}/test_modify\"\n",
    "    if not os.path.exists(test_dir):\n",
    "        test_dir = f\"{global_config['DATA_ROOT']}/test\"\n",
    "        print(f\"'{test_dir}' not found. Using original test directory: '{test_dir}'\")\n",
    "\n",
    "    submission_df = pd.read_csv(f\"{global_config['DATA_ROOT']}/sample_submission.csv\")\n",
    "    \n",
    "    # ì¶”ë¡ ì—ëŠ” ê°„ë‹¨í•œ ë¦¬ì‚¬ì´ì¦ˆì™€ í…ì„œ ë³€í™˜ë§Œ ì‚¬ìš©\n",
    "    _, test_transform = build_unified_transforms(load_config(global_config['MODELS'][0]['config_path'])[\"transforms\"][\"val\"])\n",
    "    \n",
    "    DatasetClass = get_dataset('BaseDataset') # ì¶”ë¡  ì‹œì—ëŠ” ê°„ë‹¨í•œ ë°ì´í„°ì…‹ ì‚¬ìš©\n",
    "    test_dataset = DatasetClass(df=submission_df, data_root=test_dir, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=global_config['INFERENCE']['batch_size'], shuffle=False, num_workers=os.cpu_count()//2)\n",
    "\n",
    "    # --- TTA ë³€í™˜ ì¤€ë¹„ ---\n",
    "    tta_transforms = None\n",
    "    if global_config['INFERENCE']['use_tta']:\n",
    "        tta_transforms = build_tta_transforms(global_config['INFERENCE']['tta_transforms'])\n",
    "        print(f\"TTA enabled with {len(tta_transforms)} transforms.\")\n",
    "\n",
    "    # --- ì•™ìƒë¸” ì¶”ë¡  ---\n",
    "    all_model_probs = []\n",
    "    model_weights = []\n",
    "\n",
    "    for model_cfg in global_config['MODELS']:\n",
    "        model_name = model_cfg['model_name']\n",
    "        cfg = load_config(model_cfg['config_path'])\n",
    "        \n",
    "        # í•´ë‹¹ ëª¨ë¸ì˜ ëª¨ë“  Fold ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì°¾ê¸°\n",
    "        fold_checkpoints = sorted(glob.glob(f\"{global_config['OUTPUT_ROOT']}/{model_name}_fold*_checkpoint.pth\"))\n",
    "        if not fold_checkpoints:\n",
    "            print(f\"âš ï¸ WARNING: No checkpoints found for model '{model_name}'. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n--- Inferencing with {model_name} ({len(fold_checkpoints)} folds) ---\")\n",
    "        model_weights.append(model_cfg['weight'])\n",
    "        \n",
    "        model_fold_probs = []\n",
    "        ModelClass = get_model(cfg['MODEL'])\n",
    "\n",
    "        for fold_path in fold_checkpoints:\n",
    "            print(f\"Loading: {os.path.basename(fold_path)}\")\n",
    "            model = ModelClass(num_classes=global_config['NUM_CLASSES']).to(device)\n",
    "            model.load_state_dict(torch.load(fold_path, map_location=device))\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fold_preds = []\n",
    "                for images, _, _ in tqdm(test_loader, desc=f\"Fold {os.path.basename(fold_path)}\", leave=False):\n",
    "                    images = images.to(device)\n",
    "                    \n",
    "                    if tta_transforms:\n",
    "                        # TTA ì ìš©\n",
    "                        avg_probs = get_tta_predictions(model, images, tta_transforms, device)\n",
    "                        fold_preds.append(avg_probs)\n",
    "                    else:\n",
    "                        # TTA ë¯¸ì ìš©\n",
    "                        outputs = model(images)\n",
    "                        probs = torch.softmax(outputs, dim=1)\n",
    "                        fold_preds.append(probs.cpu())\n",
    "\n",
    "            model_fold_probs.append(torch.cat(fold_preds, dim=0))\n",
    "            \n",
    "            del model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # ê° Foldì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í‰ê· \n",
    "        avg_model_probs = torch.stack(model_fold_probs, dim=0).mean(dim=0)\n",
    "        all_model_probs.append(avg_model_probs)\n",
    "\n",
    "    if not all_model_probs:\n",
    "        print(\"âŒ ERROR: No models were successfully inferenced. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # --- ê°€ì¤‘ ì•™ìƒë¸” ---\n",
    "    print(\"\\n--- Performing weighted ensemble ---\")\n",
    "    # ê°€ì¤‘ì¹˜ ì •ê·œí™”\n",
    "    total_weight = sum(model_weights)\n",
    "    normalized_weights = [w / total_weight for w in model_weights]\n",
    "\n",
    "    final_probs = torch.zeros_like(all_model_probs[0])\n",
    "    for probs, weight in zip(all_model_probs, normalized_weights):\n",
    "        final_probs += probs * weight\n",
    "\n",
    "    final_predictions = torch.argmax(final_probs, dim=1).numpy()\n",
    "\n",
    "    # --- ì œì¶œ íŒŒì¼ ìƒì„± ---\n",
    "    submission_df['target'] = final_predictions\n",
    "    submission_path = os.path.join(global_config['OUTPUT_ROOT'], global_config['INFERENCE']['submission_filename'])\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"\\nğŸ‰ Inference finished! Submission file saved to: {submission_path} ğŸ‰\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"K-Fold Ensemble Training and Inference Pipeline\")\n",
    "    parser.add_argument('--mode', type=str, required=True, choices=['train', 'inference'],\n",
    "                        help=\"Set the pipeline to 'train' or 'inference' mode.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # ì¤‘ì•™ ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "    global_config = load_config(\"config/kfold_ensemble_config.yaml\")\n",
    "    \n",
    "    # ì¶œë ¥ í´ë” ìƒì„±\n",
    "    os.makedirs(global_config['OUTPUT_ROOT'], exist_ok=True)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "        train_pipeline(global_config)\n",
    "    elif args.mode == 'inference':\n",
    "        inference_pipeline(global_config)\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ 3ë‹¨ê³„: ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "ì´ì œ ëª¨ë“  ì¤€ë¹„ê°€ ëë‚¬ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "#### **1. (ì„ íƒ) í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬**\n",
    "ë§Œì•½ `test_data_preprocess.py`ë¥¼ ì‚¬ìš©í•˜ì‹ ë‹¤ë©´, ê°€ì¥ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "```bash\n",
    "python test_data_preprocess.py\n",
    "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ./data/test ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ./data/test_modify í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤. run_kfold_ensemble.pyëŠ” ì´ í´ë”ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. K-Fold í•™ìŠµ ì‹œì‘\n",
    "ì•„ë˜ ëª…ë ¹ì–´ë¡œ train ëª¨ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ëŠ” kfold_ensemble_config.yamlì„ ì½ì–´ ì •ì˜ëœ ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ K-Fold í•™ìŠµì„ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰í•˜ê³ , ê° Foldì˜ ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ./output í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "bash\n",
    "python run_kfold_ensemble.py --mode train\n",
    "3. ì•™ìƒë¸” ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "í•™ìŠµì´ ëª¨ë‘ ëë‚˜ë©´, ì•„ë˜ ëª…ë ¹ì–´ë¡œ inference ëª¨ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ê°€ ./output í´ë”ì—ì„œ í•™ìŠµëœ ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ TTAì™€ ê°€ì¤‘ ì•™ìƒë¸”ì„ ì ìš©í•œ í›„, ìµœì¢… ì œì¶œ íŒŒì¼(submission_ensemble.csv)ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "bash\n",
    "python run_kfold_ensemble.py --mode inference\n",
    "ì´ì œ ì´ ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ í›¨ì”¬ ë” ì²´ê³„ì ì´ê³  ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ ì‹¤í—˜ì„ ê´€ë¦¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„±ê³µì ì¸ ê²°ê³¼ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4d200",
   "metadata": {},
   "source": [
    "ë„ˆê°€ ìœ„ì— ë§í–ˆë˜ê²ƒë“¤ ì „ë¶€ ë‹¤ì‹œ ë°˜ì˜í•´ì„œ ì½”ë“œ ë§Œë“¤ì–´ì¤˜\n",
    "\n",
    "\n",
    "Gemini\n",
    "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤! ì§€ê¸ˆê¹Œì§€ ë…¼ì˜í–ˆë˜ ëª¨ë“  ê°œì„  ì‚¬í•­â€”ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹, K-Fold êµì°¨ ê²€ì¦, TTA, ê·¸ë¦¬ê³  ê°€ì¤‘ ì•™ìƒë¸”â€”ì„ ëª¨ë‘ í†µí•©í•œ ìµœì¢… ì½”ë“œë¥¼ ë‹¤ì‹œ ë§Œë“¤ì–´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ëŸ¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë³µì¡í•˜ê²Œ ì‹¤í–‰í•  í•„ìš” ì—†ì´, ë‹¨ í•˜ë‚˜ì˜ í†µí•© ìŠ¤í¬ë¦½íŠ¸(run_kfold_ensemble.py)ì™€ ì„¤ì • íŒŒì¼(kfold_ensemble_config.yaml)ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì œì–´í•˜ë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° ìš”ì•½\n",
    "ì¤‘ì•™ ì„¤ì • (kfold_ensemble_config.yaml): ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë“  ëª¨ë¸, K-Fold ì„¤ì •, TTA, ê°€ì¤‘ì¹˜ ë“±ì„ ì´ íŒŒì¼ í•˜ë‚˜ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "í†µí•© ì‹¤í–‰ (run_kfold_ensemble.py): ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ --mode ì˜µì…˜ê³¼ í•¨ê»˜ ì‹¤í–‰í•˜ì—¬ í•™ìŠµê³¼ ì¶”ë¡ ì„ ëª¨ë‘ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "--mode train: ì„¤ì • íŒŒì¼ì— ì •ì˜ëœ ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ K-Fold í•™ìŠµì„ ì‹¤í–‰í•˜ê³ , ê° Foldì˜ ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ì²´í¬í¬ì¸íŠ¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "--mode inference: ì €ì¥ëœ ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ TTAì™€ ê°€ì¤‘ ì•™ìƒë¸”ì„ ì ìš©í•˜ì—¬ ìµœì¢… ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "1. ì¤‘ì•™ ì„¤ì • íŒŒì¼ (kfold_ensemble_config.yaml)\n",
    "ë¨¼ì €, í”„ë¡œì íŠ¸ì˜ \"ì¡°ì¢…ì„\" ì—­í• ì„ í•  ì„¤ì • íŒŒì¼ì…ë‹ˆë‹¤. ì œê³µí•´ì£¼ì‹  ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë²„ì „ì„ ë‹¤ì‹œ í™•ì¸í•©ë‹ˆë‹¤. ì´ íŒŒì¼ì€ config/ í´ë”ì— ìœ„ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "yaml\n",
    "# /root/DTC/upstageailab-cv-classification-cv_6/config/kfold_ensemble_config.yaml\n",
    "\n",
    "# Global settings for K-Fold and Ensemble\n",
    "SEED: 42\n",
    "N_SPLITS: 5 # K-Foldì˜ K ê°’\n",
    "DATA_ROOT: './data'\n",
    "OUTPUT_ROOT: './output'\n",
    "NUM_CLASSES: 17\n",
    "\n",
    "# ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\n",
    "# ê° ëª¨ë¸ì€ ê³ ìœ í•œ í•™ìŠµ ì„¤ì •(config_path)ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "MODELS:\n",
    "  - # --- ëª¨ë¸ A: ResNeSt101e ---\n",
    "    model_name: \"ResNeSt101e\" # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ëª…ì— ì‚¬ìš©ë  ê³ ìœ  ì´ë¦„\n",
    "    config_path: \"config/main_config.yaml\" # ì´ ëª¨ë¸ì— ëŒ€í•œ í•™ìŠµ ì„¤ì • íŒŒì¼\n",
    "    weight: 0.4 # ì•™ìƒë¸” ê°€ì¤‘ì¹˜\n",
    "\n",
    "  - # --- ëª¨ë¸ B: EfficientNetV2 (ê°€ì •) ---\n",
    "    model_name: \"EfficientNetV2\"\n",
    "    # main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL, model_type ë“±ë§Œ ë°”ê¿”ì„œ ì‚¬ìš©\n",
    "    config_path: \"config/effnet_config.yaml\" # ì˜ˆì‹œ íŒŒì¼ëª…\n",
    "    weight: 0.3\n",
    "\n",
    "  - # --- ëª¨ë¸ C: ConvNeXt (ê°€ì •) ---\n",
    "    model_name: \"ConvNeXt\"\n",
    "    # main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL, model_type ë“±ë§Œ ë°”ê¿”ì„œ ì‚¬ìš©\n",
    "    config_path: \"config/convnext_config.yaml\" # ì˜ˆì‹œ íŒŒì¼ëª…\n",
    "    weight: 0.3\n",
    "\n",
    "# ì¶”ë¡  ì‹œ ì„¤ì •\n",
    "INFERENCE:\n",
    "  batch_size: 16\n",
    "  use_tta: True\n",
    "  submission_filename: \"submission_ensemble.csv\"\n",
    "  # TTAì— ì‚¬ìš©í•  ë³€í™˜ ë¦¬ìŠ¤íŠ¸ (torchvision.transforms.v2 í˜•ì‹)\n",
    "  tta_transforms:\n",
    "    - name: \"HorizontalFlip\"\n",
    "      params: { p: 1.0 }\n",
    "    - name: \"RandomRotation\"\n",
    "      params: { degrees: 15 }\n",
    "    - name: \"RandomRotation\"\n",
    "      params: { degrees: -15 }\n",
    "ì¤‘ìš”: MODELS ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê° ëª¨ë¸ì˜ config_path (ì˜ˆ: config/effnet_config.yaml)ëŠ” ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì´ì–´ì•¼ í•©ë‹ˆë‹¤. main_config.yamlì„ ë³µì‚¬í•˜ì—¬ MODEL, model_type ë“±ë§Œ ìˆ˜ì •í•´ì„œ ì—¬ëŸ¬ ê°œë¥¼ ë§Œë“¤ì–´ë‘ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "2. í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (run_kfold_ensemble.py)\n",
    "ê¸°ì¡´ì˜ main.py, main_test.py, inference_ensemble.pyì˜ í•µì‹¬ ê¸°ëŠ¥ë“¤ì„ ëª¨ë‘ í•©ì¹œ í†µí•© ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ í´ë”ì— ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ run_kfold_ensemble.py íŒŒì¼ì„ ìƒˆë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "New file: run_kfold_ensemble.py\n",
    "+309\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import argparse\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config.config import load_config\n",
    "from utils.utils import *\n",
    "from datasets.transforms import build_unified_transforms, build_tta_transforms\n",
    "\n",
    "from datasets import get_dataset\n",
    "from models import get_model\n",
    "\n",
    "from utils.EarlyStopping import EarlyStopping\n",
    "from utils.scheduler_factory import get_scheduler\n",
    "from utils.optimizer_factory import get_optimizer\n",
    "from utils.loss_factory import get_loss\n",
    "from trainer import *\n",
    "from trainer.wandb_logger import WandbLogger\n",
    "from utils.predict_tta import get_tta_predictions\n",
    "\n",
    "# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (main.pyì—ì„œ ê°€ì ¸ì˜´) ---\n",
    "\n",
    "def setup_optimizer_params(model: nn.Module, model_type: str, num_layers_to_unfreeze: int, backbone_lr: float, head_lr: float, use_differential_lr: bool):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model_type_lower = model_type.lower()\n",
    "    backbone = model.backbone\n",
    "    \n",
    "    stages_to_unfreeze = []\n",
    "    if num_layers_to_unfreeze > 0:\n",
    "        if model_type_lower.startswith('resnet'):\n",
    "            all_stages = [backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4]\n",
    "        elif model_type_lower.startswith('swin'): all_stages = backbone.layers\n",
    "        elif model_type_lower.startswith('convnext'): all_stages = backbone.stages\n",
    "        else: all_stages = backbone.blocks # efficientnet\n",
    "        \n",
    "        if num_layers_to_unfreeze > len(all_stages): num_layers_to_unfreeze = len(all_stages)\n",
    "        stages_to_unfreeze = all_stages[-num_layers_to_unfreeze:]\n",
    "\n",
    "    for stage in stages_to_unfreeze:\n",
    "        for param in stage.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if hasattr(model, 'neck'):\n",
    "        for param in model.neck.parameters(): param.requires_grad = True\n",
    "    if hasattr(model, 'head'):\n",
    "        for param in model.head.parameters(): param.requires_grad = True\n",
    "            \n",
    "    param_groups = []\n",
    "    if use_differential_lr:\n",
    "        backbone_params = list(filter(lambda p: p.requires_grad, model.backbone.parameters()))\n",
    "        if backbone_params: param_groups.append({\"params\": backbone_params, \"lr\": backbone_lr})\n",
    "\n",
    "        if hasattr(model, 'neck'):\n",
    "            neck_params = list(filter(lambda p: p.requires_grad, model.neck.parameters()))\n",
    "            if neck_params: param_groups.append({\"params\": neck_params, \"lr\": head_lr})\n",
    "\n",
    "        if hasattr(model, 'head'):\n",
    "            head_params = list(filter(lambda p: p.requires_grad, model.head.parameters()))\n",
    "            if head_params: param_groups.append({\"params\": head_params, \"lr\": head_lr})\n",
    "    else:\n",
    "        param_groups = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "    return param_groups\n",
    "\n",
    "# --- í•™ìŠµ íŒŒì´í”„ë¼ì¸ ---\n",
    "\n",
    "def run_fold_training(\n",
    "    fold: int,\n",
    "    model_config: dict,\n",
    "    global_config: dict,\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    device: torch.device\n",
    "):\n",
    "    # --- ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
    "    cfg = load_config(model_config['config_path'])\n",
    "    model_name = model_config['model_name']\n",
    "    \n",
    "    print(f\"\\n===== FOLD {fold+1}/{global_config['N_SPLITS']} | MODEL: {model_name} | CONFIG: {model_config['config_path']} =====\")\n",
    "    \n",
    "    set_seed(global_config['SEED'] + fold) # Foldë§ˆë‹¤ ë‹¤ë¥¸ ì‹œë“œ ì ìš©\n",
    "\n",
    "    # --- ë°ì´í„°ì…‹ ë° ë¡œë” ---\n",
    "    train_transform, val_transform = build_unified_transforms(cfg[\"transforms\"][\"train\"]), build_unified_transforms(cfg[\"transforms\"][\"val\"])\n",
    "    DatasetClass = get_dataset(cfg['DATASET'])\n",
    "    train_dataset = DatasetClass(df=train_df, data_root=f\"{global_config['DATA_ROOT']}/train/\", transform=train_transform)\n",
    "    val_dataset = DatasetClass(df=val_df, data_root=f\"{global_config['DATA_ROOT']}/train/\", transform=val_transform)\n",
    "    \n",
    "    sampler = setting_sampler(train_df)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg[\"BATCH_SIZE\"], sampler=sampler, num_workers=os.cpu_count()//2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg[\"BATCH_SIZE\"], shuffle=False, num_workers=os.cpu_count()//2, pin_memory=True)\n",
    "\n",
    "    # --- ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ë¡œê±° ---\n",
    "    ModelClass = get_model(cfg['MODEL'])\n",
    "    model = ModelClass(num_classes=global_config['NUM_CLASSES']).to(device)\n",
    "    criterion = get_loss(cfg[\"loss\"][\"name\"], cfg[\"loss\"][\"params\"])\n",
    "    \n",
    "    date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    run_name = f\"{model_name}_fold{fold+1}_{date}\"\n",
    "    save_path = f\"{global_config['OUTPUT_ROOT']}/{run_name}_checkpoint.pth\"\n",
    "    \n",
    "    logger = WandbLogger(\n",
    "        project_name=\"DTC-KFold-Ensemble\",\n",
    "        run_name=run_name,\n",
    "        config=cfg,\n",
    "        save_path=save_path\n",
    "    )\n",
    "\n",
    "    # --- 1ë‹¨ê³„: í—¤ë“œ í•™ìŠµ ---\n",
    "    print(\"\\n--- STAGE 1: HEAD TRAINING ---\")\n",
    "    if cfg['head_only_epochs'] > 0:\n",
    "        head_params = setup_optimizer_params(model, cfg[\"model_type\"], 0, 0, cfg[\"head_only_lr\"], False)\n",
    "        optimizer_head = get_optimizer(cfg[\"optimizer\"][\"name\"], head_params, {\"lr\": cfg[\"head_only_lr\"]})\n",
    "        \n",
    "        scheduler_params_s1 = cfg[\"scheduler\"][\"params\"].copy()\n",
    "        scheduler_params_s1['max_lr'] = cfg[\"head_only_lr\"]\n",
    "        scheduler_params_s1['total_steps'] = len(train_loader) * cfg[\"head_only_epochs\"]\n",
    "        if scheduler_params_s1['total_steps'] == 0: scheduler_params_s1['total_steps'] = 1\n",
    "        scheduler_head = get_scheduler(cfg[\"scheduler\"][\"name\"], optimizer_head, scheduler_params_s1)\n",
    "        \n",
    "        training_loop(\n",
    "            TRAINING_REGISTRY[cfg['training_mode']], model, train_loader, val_loader, train_dataset, val_dataset, \n",
    "            criterion, optimizer_head, device, cfg[\"head_only_epochs\"], None, logger, None, scheduler_head, {}\n",
    "        )\n",
    "\n",
    "    # --- 2ë‹¨ê³„: ì „ì²´ ë¯¸ì„¸ ì¡°ì • ---\n",
    "    print(\"\\n--- STAGE 2: FULL FINE-TUNING ---\")\n",
    "    params_to_update = setup_optimizer_params(\n",
    "        model, cfg[\"model_type\"], cfg[\"num_blocks_to_unfreeze\"],\n",
    "        cfg[\"backbone_lr\"], cfg[\"optimizer\"][\"params\"][\"lr\"], cfg[\"use_differential_lr\"]\n",
    "    )\n",
    "    optimizer = get_optimizer(cfg[\"optimizer\"][\"name\"], params_to_update, cfg[\"optimizer\"][\"params\"])\n",
    "    \n",
    "    scheduler_params_s2 = cfg[\"scheduler\"][\"params\"].copy()\n",
    "    max_lrs = [pg.get('lr', cfg['optimizer']['params']['lr']) for pg in optimizer.param_groups]\n",
    "    scheduler_params_s2['max_lr'] = max_lrs\n",
    "    scheduler_params_s2['total_steps'] = len(train_loader) * cfg[\"EPOCHS\"]\n",
    "    scheduler = get_scheduler(cfg[\"scheduler\"][\"name\"], optimizer, scheduler_params_s2)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=cfg[\"patience\"], delta=cfg[\"delta\"], verbose=True, save_path=save_path, mode='max')\n",
    "    training_args = {'scaler': GradScaler()} if cfg[\"training_mode\"] == 'on_amp' else {}\n",
    "\n",
    "    training_loop(\n",
    "        TRAINING_REGISTRY[cfg['training_mode']], model, train_loader, val_loader, train_dataset, val_dataset, \n",
    "        criterion, optimizer, device, cfg[\"EPOCHS\"], early_stopping, logger, None, scheduler, training_args\n",
    "    )\n",
    "\n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del model, optimizer, scheduler, train_loader, val_loader, logger, early_stopping\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def train_pipeline(global_config):\n",
    "    print(\"ğŸš€ STARTING K-FOLD TRAINING PIPELINE ğŸš€\")\n",
    "    \n",
    "    # ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\n",
    "    full_train_df = pd.read_csv(f\"{global_config['DATA_ROOT']}/train_valid_set/train-label-fix-v1.csv\")\n",
    "    \n",
    "    # K-Fold ë¶„í• ê¸° ì„¤ì •\n",
    "    skf = StratifiedKFold(n_splits=global_config['N_SPLITS'], shuffle=True, random_state=global_config['SEED'])\n",
    "\n",
    "    for model_cfg in global_config['MODELS']:\n",
    "        # K-Fold ë£¨í”„ ì‹¤í–‰\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(full_train_df, full_train_df['target'])):\n",
    "            train_df = full_train_df.iloc[train_idx]\n",
    "            val_df = full_train_df.iloc[val_idx]\n",
    "            \n",
    "            run_fold_training(\n",
    "                fold=fold,\n",
    "                model_config=model_cfg,\n",
    "                global_config=global_config,\n",
    "                train_df=train_df,\n",
    "                val_df=val_df,\n",
    "                device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            )\n",
    "    print(\"\\nğŸ‰ ALL K-FOLD TRAINING FINISHED! ğŸ‰\")\n",
    "\n",
    "\n",
    "# --- ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ---\n",
    "\n",
    "def inference_pipeline(global_config):\n",
    "    print(\"ğŸš€ STARTING ENSEMBLE INFERENCE PIPELINE ğŸš€\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # --- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ ---\n",
    "    # test_data_preprocess.pyë¥¼ ì‹¤í–‰í–ˆë‹¤ë©´ test_modify í´ë” ì‚¬ìš©\n",
    "    test_dir = f\"{global_config['DATA_ROOT']}/test_modify\"\n",
    "    if not os.path.exists(test_dir) or not os.listdir(test_dir):\n",
    "        test_dir = f\"{global_config['DATA_ROOT']}/test\"\n",
    "        print(f\"'{global_config['DATA_ROOT']}/test_modify' not found or empty. Using original test directory: '{test_dir}'\")\n",
    "\n",
    "    submission_df = pd.read_csv(f\"{global_config['DATA_ROOT']}/sample_submission.csv\")\n",
    "    \n",
    "    # ì¶”ë¡ ì—ëŠ” ê°„ë‹¨í•œ ë¦¬ì‚¬ì´ì¦ˆì™€ í…ì„œ ë³€í™˜ë§Œ ì‚¬ìš© (ì²« ë²ˆì§¸ ëª¨ë¸ì˜ val transform ê¸°ì¤€)\n",
    "    _, test_transform = build_unified_transforms(load_config(global_config['MODELS'][0]['config_path'])[\"transforms\"][\"val\"])\n",
    "    \n",
    "    DatasetClass = get_dataset('BaseDataset') # ì¶”ë¡  ì‹œì—ëŠ” ê°„ë‹¨í•œ ë°ì´í„°ì…‹ ì‚¬ìš©\n",
    "    test_dataset = DatasetClass(df=submission_df, data_root=test_dir, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=global_config['INFERENCE']['batch_size'], shuffle=False, num_workers=os.cpu_count()//2)\n",
    "\n",
    "    # --- TTA ë³€í™˜ ì¤€ë¹„ ---\n",
    "    tta_transforms = None\n",
    "    if global_config['INFERENCE']['use_tta']:\n",
    "        tta_transforms = build_tta_transforms(global_config['INFERENCE']['tta_transforms'])\n",
    "        print(f\"TTA enabled with {len(tta_transforms)} transforms.\")\n",
    "\n",
    "    # --- ì•™ìƒë¸” ì¶”ë¡  ---\n",
    "    all_model_probs = []\n",
    "    model_weights = []\n",
    "\n",
    "    for model_cfg in global_config['MODELS']:\n",
    "        model_name = model_cfg['model_name']\n",
    "        cfg = load_config(model_cfg['config_path'])\n",
    "        \n",
    "        # í•´ë‹¹ ëª¨ë¸ì˜ ëª¨ë“  Fold ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì°¾ê¸°\n",
    "        fold_checkpoints = sorted(glob.glob(f\"{global_config['OUTPUT_ROOT']}/{model_name}_fold*_checkpoint.pth\"))\n",
    "        if not fold_checkpoints:\n",
    "            print(f\"âš ï¸ WARNING: No checkpoints found for model '{model_name}'. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n--- Inferencing with {model_name} ({len(fold_checkpoints)} folds) ---\")\n",
    "        model_weights.append(model_cfg['weight'])\n",
    "        \n",
    "        model_fold_probs = []\n",
    "        ModelClass = get_model(cfg['MODEL'])\n",
    "\n",
    "        for fold_path in fold_checkpoints:\n",
    "            print(f\"Loading: {os.path.basename(fold_path)}\")\n",
    "            model = ModelClass(num_classes=global_config['NUM_CLASSES']).to(device)\n",
    "            model.load_state_dict(torch.load(fold_path, map_location=device))\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fold_preds = []\n",
    "                for images, _, _ in tqdm(test_loader, desc=f\"Fold {os.path.basename(fold_path).split('_')[1]}\", leave=False):\n",
    "                    images = images.to(device)\n",
    "                    \n",
    "                    if tta_transforms:\n",
    "                        # TTA ì ìš©\n",
    "                        avg_probs = get_tta_predictions(model, images, tta_transforms, device)\n",
    "                        fold_preds.append(avg_probs)\n",
    "                    else:\n",
    "                        # TTA ë¯¸ì ìš©\n",
    "                        outputs = model(images)\n",
    "                        probs = torch.softmax(outputs, dim=1)\n",
    "                        fold_preds.append(probs.cpu())\n",
    "\n",
    "            model_fold_probs.append(torch.cat(fold_preds, dim=0))\n",
    "            \n",
    "            del model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # ê° Foldì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í‰ê· \n",
    "        avg_model_probs = torch.stack(model_fold_probs, dim=0).mean(dim=0)\n",
    "        all_model_probs.append(avg_model_probs)\n",
    "\n",
    "    if not all_model_probs:\n",
    "        print(\"âŒ ERROR: No models were successfully inferenced. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # --- ê°€ì¤‘ ì•™ìƒë¸” ---\n",
    "    print(\"\\n--- Performing weighted ensemble ---\")\n",
    "    # ê°€ì¤‘ì¹˜ ì •ê·œí™”\n",
    "    total_weight = sum(model_weights)\n",
    "    normalized_weights = [w / total_weight for w in model_weights]\n",
    "\n",
    "    final_probs = torch.zeros_like(all_model_probs[0])\n",
    "    for probs, weight in zip(all_model_probs, normalized_weights):\n",
    "        final_probs += probs * weight\n",
    "\n",
    "    final_predictions = torch.argmax(final_probs, dim=1).numpy()\n",
    "\n",
    "    # --- ì œì¶œ íŒŒì¼ ìƒì„± ---\n",
    "    submission_df['target'] = final_predictions\n",
    "    submission_path = os.path.join(global_config['OUTPUT_ROOT'], global_config['INFERENCE']['submission_filename'])\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"\\nğŸ‰ Inference finished! Submission file saved to: {submission_path} ğŸ‰\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"K-Fold Ensemble Training and Inference Pipeline\")\n",
    "    parser.add_argument('--mode', type=str, required=True, choices=['train', 'inference'],\n",
    "                        help=\"Set the pipeline to 'train' or 'inference' mode.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # ì¤‘ì•™ ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "    global_config = load_config(\"config/kfold_ensemble_config.yaml\")\n",
    "    \n",
    "    # ì¶œë ¥ í´ë” ìƒì„±\n",
    "    os.makedirs(global_config['OUTPUT_ROOT'], exist_ok=True)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "        train_pipeline(global_config)\n",
    "    elif args.mode == 'inference':\n",
    "        inference_pipeline(global_config)\n",
    "\n",
    "ğŸš€ 3. ì‹¤í–‰ ë°©ë²•\n",
    "ì´ì œ ëª¨ë“  ì¤€ë¹„ê°€ ëë‚¬ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "1. (ì„ íƒ) í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "ë§Œì•½ test_data_preprocess.pyë¥¼ ì‚¬ìš©í•˜ì‹ ë‹¤ë©´, ê°€ì¥ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ./data/test ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ./data/test_modify í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤. ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ëŠ” ì´ í´ë”ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "bash\n",
    "python test_data_preprocess.py\n",
    "2. K-Fold í•™ìŠµ ì‹œì‘\n",
    "ì•„ë˜ ëª…ë ¹ì–´ë¡œ train ëª¨ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ëŠ” kfold_ensemble_config.yamlì„ ì½ì–´ ì •ì˜ëœ ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ K-Fold í•™ìŠµì„ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰í•˜ê³ , ê° Foldì˜ ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ./output í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "bash\n",
    "python run_kfold_ensemble.py --mode train\n",
    "3. ì•™ìƒë¸” ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "í•™ìŠµì´ ëª¨ë‘ ëë‚˜ë©´, ì•„ë˜ ëª…ë ¹ì–´ë¡œ inference ëª¨ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ê°€ ./output í´ë”ì—ì„œ í•™ìŠµëœ ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ TTAì™€ ê°€ì¤‘ ì•™ìƒë¸”ì„ ì ìš©í•œ í›„, ìµœì¢… ì œì¶œ íŒŒì¼(submission_ensemble.csv)ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "bash\n",
    "python run_kfold_ensemble.py --mode inference\n",
    "ì´ ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ í›¨ì”¬ ë” ì²´ê³„ì ì´ê³  ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ ì‹¤í—˜ì„ ê´€ë¦¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„±ê³µì ì¸ ê²°ê³¼ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
