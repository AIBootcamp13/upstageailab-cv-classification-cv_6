# í•œêµ­ ë¬¸ì„œ ë¶„ë¥˜ í”„ë¡œì íŠ¸ - í–¥ìƒëœ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (Enhanced EDA)
# ì´ ì½”ë“œëŠ” 17ê°€ì§€ ì¢…ë¥˜ì˜ í•œêµ­ ë¬¸ì„œ(ì‹ ë¶„ì¦, ì˜ë£Œì„œë¥˜ ë“±)ë¥¼ ë¶„ë¥˜í•˜ëŠ” AI ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•œ ë°ì´í„° ë¶„ì„ì…ë‹ˆë‹¤.

# ğŸ“š í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ ë¶ˆëŸ¬ì˜¤ê¸°
import os
from collections import defaultdict, Counter
import pandas as pd
import numpy as np
from PIL import Image, ImageStat
import cv2
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import seaborn as sns
import torch
import torchvision.models as models
import torchvision.transforms as T
from tqdm import tqdm
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

# ğŸ¨ ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •
plt.rcParams['font.family'] = ['DejaVu Sans', 'NanumGothic', 'Malgun Gothic']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")

print("âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ")
print("âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ")

# ğŸ“ ë°ì´í„° ê²½ë¡œ ì„¤ì •
class Config:
    """ì„¤ì • í´ë˜ìŠ¤"""
    data_path = './data'
    train_csv_path = f'{data_path}/labels_updated.csv'
    meta_path = f'{data_path}/meta.csv'
    train_img_path = f'{data_path}/train'
    test_data_path = f'{data_path}/test'
    output_path = f'{data_path}/train_valid_set'
    
    # EDA ì„¤ì •
    n_sample_images = 3  # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ì´ë¯¸ì§€ ê°œìˆ˜
    aspect_ratio_bins = 5  # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ êµ¬ê°„ ê°œìˆ˜
    random_state = 42

config = Config()

# ğŸ“Š ë°ì´í„° ë¡œë” í´ë˜ìŠ¤
class DocumentDataAnalyzer:
    """ë¬¸ì„œ ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, config):
        self.config = config
        self.data_df = None
        self.meta_df = None
        self.class_map = None
        self.size_analysis_df = None
        
    def load_data(self):
        """ë°ì´í„° íŒŒì¼ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("ğŸ“Š ë°ì´í„° íŒŒì¼ ë¡œë”© ì¤‘...")
        
        # CSV íŒŒì¼ ì½ê¸°
        self.data_df = pd.read_csv(self.config.train_csv_path, header=0)
        self.meta_df = pd.read_csv(self.config.meta_path)
        
        # íƒ€ì… ë³€í™˜
        self.data_df["target"] = self.data_df["target"].astype(int)
        self.meta_df["target"] = self.meta_df["target"].astype(int)
        
        # í´ë˜ìŠ¤ ë§¤í•‘ ìƒì„±
        self.class_map = dict(zip(self.meta_df["target"], self.meta_df["class_name"]))
        
        print(f"âœ… í›ˆë ¨ ë°ì´í„°: {len(self.data_df)}ê°œ")
        print(f"âœ… í´ë˜ìŠ¤ ê°œìˆ˜: {len(self.meta_df)}ê°œ")
        
        return self
    
    def analyze_class_distribution(self):
        """í´ë˜ìŠ¤ë³„ ë°ì´í„° ë¶„í¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        print("\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ ì¤‘...")
        
        # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ê³„ì‚°
        label_counts = self.data_df["target"].value_counts().sort_index()
        label_dist = pd.DataFrame({
            'target': label_counts.index,
            'count': label_counts.values
        })
        
        # í´ë˜ìŠ¤ ì´ë¦„ ì¶”ê°€
        label_dist = pd.merge(label_dist, self.meta_df, on="target")
        
        # í†µê³„ ì¶œë ¥
        print(f"\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ë°ì´í„° ê°œìˆ˜:")
        print(label_dist[["target", "class_name", "count"]].to_string(index=False))
        
        print(f"\nâš ï¸ ë°ì´í„° ë¶ˆê· í˜• ë¶„ì„:")
        print(f"   ìµœëŒ€: {label_dist['count'].max()}ê°œ")
        print(f"   ìµœì†Œ: {label_dist['count'].min()}ê°œ")
        print(f"   í‰ê· : {label_dist['count'].mean():.1f}ê°œ")
        print(f"   í‘œì¤€í¸ì°¨: {label_dist['count'].std():.1f}")
        print(f"   ë¶ˆê· í˜• ë¹„ìœ¨: {label_dist['count'].max() / label_dist['count'].min():.2f}ë°°")
        
        return label_dist
    
    def plot_class_distribution(self, label_dist):
        """í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        fig, axes = plt.subplots(2, 1, figsize=(15, 12))
        
        # 1. ë§‰ëŒ€ ê·¸ë˜í”„
        ax1 = axes[0]
        bars = ax1.bar(range(len(label_dist)), label_dist['count'], 
                      color=sns.color_palette("husl", len(label_dist)))
        ax1.set_xlabel('ë¬¸ì„œ ì¢…ë¥˜')
        ax1.set_ylabel('ë°ì´í„° ê°œìˆ˜')
        ax1.set_title('ë¬¸ì„œ ì¢…ë¥˜ë³„ ë°ì´í„° ë¶„í¬', fontsize=14, fontweight='bold')
        ax1.set_xticks(range(len(label_dist)))
        ax1.set_xticklabels(label_dist['class_name'], rotation=45, ha='right')
        
        # ë§‰ëŒ€ ìœ„ì— ìˆ«ì í‘œì‹œ
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{int(height)}', ha='center', va='bottom', fontsize=9)
        
        ax1.grid(axis='y', alpha=0.3)
        
        # 2. íŒŒì´ ì°¨íŠ¸
        ax2 = axes[1]
        colors = sns.color_palette("husl", len(label_dist))
        wedges, texts, autotexts = ax2.pie(label_dist['count'], 
                                          labels=label_dist['class_name'],
                                          autopct='%1.1f%%',
                                          colors=colors,
                                          textprops={'fontsize': 8})
        ax2.set_title('ë¬¸ì„œ ì¢…ë¥˜ë³„ ë¹„ìœ¨', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.show()
    
    def analyze_image_dimensions(self):
        """ì´ë¯¸ì§€ í¬ê¸°ì™€ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        print("\nğŸ” ì´ë¯¸ì§€ í¬ê¸° ë° í’ˆì§ˆ ë¶„ì„ ì¤‘...")
        
        results = []
        failed_images = []
        
        for _, row in tqdm(self.data_df.iterrows(), total=len(self.data_df), 
                          desc="ì´ë¯¸ì§€ ë¶„ì„"):
            img_path = os.path.join(self.config.train_img_path, row["ID"])
            
            try:
                # OpenCVë¡œ ì´ë¯¸ì§€ ì½ê¸°
                img = cv2.imread(img_path)
                if img is None:
                    failed_images.append(row["ID"])
                    continue
                
                h, w, c = img.shape
                
                # PILë¡œ ì¶”ê°€ ì •ë³´ ì–»ê¸°
                pil_img = Image.open(img_path)
                file_size = os.path.getsize(img_path) / (1024 * 1024)  # MB
                
                # ì´ë¯¸ì§€ í†µê³„
                stat = ImageStat.Stat(pil_img)
                brightness = sum(stat.mean) / len(stat.mean)  # í‰ê·  ë°ê¸°
                
                results.append({
                    'ID': row["ID"],
                    'target': row["target"],
                    'class_name': self.class_map[row["target"]],
                    'width': w,
                    'height': h,
                    'channels': c,
                    'aspect_ratio': round(w / h, 3),
                    'total_pixels': w * h,
                    'file_size_mb': round(file_size, 3),
                    'brightness': round(brightness, 1)
                })
                
            except Exception as e:
                failed_images.append(row["ID"])
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {row['ID']} - {str(e)}")
        
        self.size_analysis_df = pd.DataFrame(results)
        
        if failed_images:
            print(f"âš ï¸ ì½ê¸° ì‹¤íŒ¨í•œ ì´ë¯¸ì§€: {len(failed_images)}ê°œ")
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì´ë¯¸ì§€")
        return self.size_analysis_df
    
    def plot_image_analysis(self):
        """ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        if self.size_analysis_df is None:
            print("âŒ ì´ë¯¸ì§€ ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        # 1. ì´ë¯¸ì§€ ë†’ì´ ë¶„í¬
        sns.histplot(data=self.size_analysis_df, x='height', bins=30, ax=axes[0])
        axes[0].set_title('ì´ë¯¸ì§€ ë†’ì´ ë¶„í¬')
        axes[0].set_xlabel('ë†’ì´ (í”½ì…€)')
        
        # 2. ì´ë¯¸ì§€ ë„ˆë¹„ ë¶„í¬
        sns.histplot(data=self.size_analysis_df, x='width', bins=30, ax=axes[1])
        axes[1].set_title('ì´ë¯¸ì§€ ë„ˆë¹„ ë¶„í¬')
        axes[1].set_xlabel('ë„ˆë¹„ (í”½ì…€)')
        
        # 3. ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ë¶„í¬
        sns.histplot(data=self.size_analysis_df, x='aspect_ratio', bins=30, ax=axes[2])
        axes[2].set_title('ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ë¶„í¬')
        axes[2].set_xlabel('ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ (W/H)')
        
        # 4. íŒŒì¼ í¬ê¸° ë¶„í¬
        sns.histplot(data=self.size_analysis_df, x='file_size_mb', bins=30, ax=axes[3])
        axes[3].set_title('íŒŒì¼ í¬ê¸° ë¶„í¬')
        axes[3].set_xlabel('íŒŒì¼ í¬ê¸° (MB)')
        
        # 5. í´ë˜ìŠ¤ë³„ í‰ê·  ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨
        class_aspect = self.size_analysis_df.groupby('class_name')['aspect_ratio'].mean().sort_values()
        sns.barplot(x=class_aspect.values, y=class_aspect.index, ax=axes[4])
        axes[4].set_title('í´ë˜ìŠ¤ë³„ í‰ê·  ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨')
        axes[4].set_xlabel('í‰ê·  ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨')
        
        # 6. ì´ í”½ì…€ ìˆ˜ vs íŒŒì¼ í¬ê¸°
        axes[5].scatter(self.size_analysis_df['total_pixels'], 
                       self.size_analysis_df['file_size_mb'], 
                       alpha=0.6, c=self.size_analysis_df['target'], cmap='tab20')
        axes[5].set_title('ì´ í”½ì…€ ìˆ˜ vs íŒŒì¼ í¬ê¸°')
        axes[5].set_xlabel('ì´ í”½ì…€ ìˆ˜')
        axes[5].set_ylabel('íŒŒì¼ í¬ê¸° (MB)')
        
        plt.tight_layout()
        plt.show()
    
    def analyze_class_characteristics(self):
        """í´ë˜ìŠ¤ë³„ íŠ¹ì„±ì„ ìƒì„¸ ë¶„ì„í•©ë‹ˆë‹¤."""
        if self.size_analysis_df is None:
            print("âŒ ì´ë¯¸ì§€ ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        print("\nğŸ“Š í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ íŠ¹ì„± ë¶„ì„:")
        
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = self.size_analysis_df.groupby('class_name').agg({
            'width': ['mean', 'std', 'min', 'max'],
            'height': ['mean', 'std', 'min', 'max'],
            'aspect_ratio': ['mean', 'std', 'min', 'max'],
            'file_size_mb': ['mean', 'std'],
            'brightness': ['mean', 'std']
        }).round(2)
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        class_stats.columns = [f'{col[0]}_{col[1]}' for col in class_stats.columns]
        
        print(class_stats.to_string())
        
        # ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨
        sns.boxplot(data=self.size_analysis_df, x='class_name', y='aspect_ratio', ax=axes[0,0])
        axes[0,0].set_title('í´ë˜ìŠ¤ë³„ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ë¶„í¬')
        axes[0,0].tick_params(axis='x', rotation=45)
        
        # íŒŒì¼ í¬ê¸°
        sns.boxplot(data=self.size_analysis_df, x='class_name', y='file_size_mb', ax=axes[0,1])
        axes[0,1].set_title('í´ë˜ìŠ¤ë³„ íŒŒì¼ í¬ê¸° ë¶„í¬')
        axes[0,1].tick_params(axis='x', rotation=45)
        
        # ë°ê¸°
        sns.boxplot(data=self.size_analysis_df, x='class_name', y='brightness', ax=axes[1,0])
        axes[1,0].set_title('í´ë˜ìŠ¤ë³„ ë°ê¸° ë¶„í¬')
        axes[1,0].tick_params(axis='x', rotation=45)
        
        # ì´ í”½ì…€ ìˆ˜
        sns.boxplot(data=self.size_analysis_df, x='class_name', y='total_pixels', ax=axes[1,1])
        axes[1,1].set_title('í´ë˜ìŠ¤ë³„ ì´ í”½ì…€ ìˆ˜ ë¶„í¬')
        axes[1,1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.show()
        
        return class_stats
    
    def stratified_split(self, test_size=0.2):
        """ê³„ì¸µì  ë¶„í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        if self.size_analysis_df is None:
            print("âŒ ì´ë¯¸ì§€ ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None, None
        
        print(f"\nğŸ”„ ê³„ì¸µì  ë°ì´í„° ë¶„í•  ì¤‘... (ê²€ì¦ ë¹„ìœ¨: {test_size*100}%)")
        
        # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ êµ¬ê°„ ìƒì„±
        self.size_analysis_df['aspect_bin'] = pd.qcut(
            self.size_analysis_df['aspect_ratio'], 
            q=self.config.aspect_ratio_bins, 
            labels=False, 
            duplicates='drop'
        )
        
        # ê³„ì¸µ ìƒì„± (í´ë˜ìŠ¤ + ë¹„ìœ¨êµ¬ê°„)
        self.size_analysis_df['strata'] = (
            self.size_analysis_df['target'].astype(str) + '_' + 
            self.size_analysis_df['aspect_bin'].astype(str)
        )
        
        # ê³„ì¸µë³„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ í™•ì¸
        strata_counts = self.size_analysis_df['strata'].value_counts()
        min_samples = 2
        
        # ì¶©ë¶„í•œ ìƒ˜í”Œì´ ìˆëŠ” ê³„ì¸µë§Œ ì‚¬ìš©
        valid_strata = strata_counts[strata_counts >= min_samples].index
        df_valid = self.size_analysis_df[
            self.size_analysis_df['strata'].isin(valid_strata)
        ].copy()
        
        # ê³„ì¸µì  ë¶„í• 
        sss = StratifiedShuffleSplit(
            n_splits=1, 
            test_size=test_size, 
            random_state=self.config.random_state
        )
        
        train_idx, val_idx = next(sss.split(df_valid, df_valid['strata']))
        
        train_df = df_valid.iloc[train_idx].reset_index(drop=True)
        val_df = df_valid.iloc[val_idx].reset_index(drop=True)
        
        # ë¶ˆì¶©ë¶„í•œ ìƒ˜í”Œì˜ ê³„ì¸µì€ ê²€ì¦ ë°ì´í„°ì— ì¶”ê°€
        df_insufficient = self.size_analysis_df[
            ~self.size_analysis_df['strata'].isin(valid_strata)
        ].copy()
        
        if len(df_insufficient) > 0:
            val_df = pd.concat([val_df, df_insufficient]).reset_index(drop=True)
        
        print(f"âœ… ë¶„í•  ì™„ë£Œ!")
        print(f"   í›ˆë ¨ ë°ì´í„°: {len(train_df)}ê°œ")
        print(f"   ê²€ì¦ ë°ì´í„°: {len(val_df)}ê°œ")
        print(f"   ì „ì²´ ë°ì´í„°: {len(train_df) + len(val_df)}ê°œ")
        
        # ë¶„í•  í’ˆì§ˆ í™•ì¸
        self._validate_split_quality(train_df, val_df)
        
        return train_df, val_df
    
    def _validate_split_quality(self, train_df, val_df):
        """ë¶„í•  í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        print("\nğŸ” ë¶„í•  í’ˆì§ˆ ê²€ì¦:")
        
        # í´ë˜ìŠ¤ë³„ ë¶„í¬ ë¹„êµ
        train_dist = train_df['target'].value_counts(normalize=True).sort_index()
        val_dist = val_df['target'].value_counts(normalize=True).sort_index()
        
        # ë¶„í¬ ì°¨ì´ ê³„ì‚°
        common_classes = train_dist.index.intersection(val_dist.index)
        if len(common_classes) > 0:
            dist_diff = abs(train_dist[common_classes] - val_dist[common_classes]).mean()
            print(f"   í‰ê·  í´ë˜ìŠ¤ ë¶„í¬ ì°¨ì´: {dist_diff:.3f}")
        
        # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ë¶„í¬ ë¹„êµ
        from scipy import stats
        aspect_stat, aspect_p = stats.ks_2samp(train_df['aspect_ratio'], val_df['aspect_ratio'])
        print(f"   ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ë¶„í¬ ìœ ì‚¬ë„ (p-value): {aspect_p:.3f}")
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        # í´ë˜ìŠ¤ ë¶„í¬ ë¹„êµ
        comparison_df = pd.DataFrame({
            'train': train_dist,
            'val': val_dist
        }).fillna(0)
        
        comparison_df.plot(kind='bar', ax=axes[0])
        axes[0].set_title('í›ˆë ¨/ê²€ì¦ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬ ë¹„êµ')
        axes[0].set_xlabel('í´ë˜ìŠ¤')
        axes[0].set_ylabel('ë¹„ìœ¨')
        axes[0].legend()
        axes[0].tick_params(axis='x', rotation=45)
        
        # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ë¶„í¬ ë¹„êµ
        sns.kdeplot(data=train_df, x='aspect_ratio', label='í›ˆë ¨', ax=axes[1])
        sns.kdeplot(data=val_df, x='aspect_ratio', label='ê²€ì¦', ax=axes[1])
        axes[1].set_title('ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ë¶„í¬ ë¹„êµ')
        axes[1].set_xlabel('ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨')
        axes[1].legend()
        
        plt.tight_layout()
        plt.show()
    
    def save_results(self, train_df, val_df):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.config.output_path, exist_ok=True)
        
        # ë¶„í• ëœ ë°ì´í„° ì €ì¥
        train_df.to_csv(f"{self.config.output_path}/train_enhanced.csv", index=False)
        val_df.to_csv(f"{self.config.output_path}/val_enhanced.csv", index=False)
        
        # ì „ì²´ ë¶„ì„ ê²°ê³¼ ì €ì¥
        if self.size_analysis_df is not None:
            self.size_analysis_df.to_csv(f"{self.config.output_path}/image_analysis.csv", index=False)
        
        print("âœ… ì €ì¥ ì™„ë£Œ!")
        print(f"   ì €ì¥ ìœ„ì¹˜: {self.config.output_path}")
    
    def generate_summary_report(self):
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        print("\nğŸ“‹ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
        print("=" * 50)
        
        if self.data_df is not None:
            print(f"ğŸ“Š ê¸°ë³¸ ì •ë³´:")
            print(f"   ì´ ì´ë¯¸ì§€ ìˆ˜: {len(self.data_df):,}ê°œ")
            print(f"   í´ë˜ìŠ¤ ìˆ˜: {len(self.meta_df)}ê°œ")
            
        if self.size_analysis_df is not None:
            print(f"\nğŸ–¼ï¸ ì´ë¯¸ì§€ íŠ¹ì„±:")
            print(f"   í‰ê·  í•´ìƒë„: {self.size_analysis_df['width'].mean():.0f} x {self.size_analysis_df['height'].mean():.0f}")
            print(f"   í‰ê·  íŒŒì¼ í¬ê¸°: {self.size_analysis_df['file_size_mb'].mean():.2f} MB")
            print(f"   í‰ê·  ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨: {self.size_analysis_df['aspect_ratio'].mean():.2f}")
            print(f"   í‰ê·  ë°ê¸°: {self.size_analysis_df['brightness'].mean():.1f}")
            
            # í´ë˜ìŠ¤ë³„ íŠ¹ì§•
            print(f"\nğŸ“ˆ í´ë˜ìŠ¤ë³„ íŠ¹ì§•:")
            for class_id, class_name in self.class_map.items():
                class_data = self.size_analysis_df[self.size_analysis_df['target'] == class_id]
                if len(class_data) > 0:
                    print(f"   {class_name}: {len(class_data)}ê°œ, "
                          f"í‰ê·  ë¹„ìœ¨ {class_data['aspect_ratio'].mean():.2f}")
        
        print(f"\nğŸ¯ ê¶Œì¥ì‚¬í•­:")
        print(f"   - ë°ì´í„° ì¦ê°• ê¸°ë²• ì ìš© (íšŒì „, í¬ê¸° ì¡°ì ˆ, ë°ê¸° ì¡°ì ˆ)")
        print(f"   - í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (ê°€ì¤‘ì¹˜ ì¡°ì • ë˜ëŠ” ìƒ˜í”Œë§)")
        print(f"   - ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í‘œì¤€í™” (í¬ê¸° ì •ê·œí™”, ë°ê¸° ë³´ì •)")
        print(f"   - êµì°¨ ê²€ì¦ì„ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦")

# ğŸš€ ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í•œêµ­ ë¬¸ì„œ ë¶„ë¥˜ í”„ë¡œì íŠ¸ EDA ì‹œì‘!")
    print("=" * 60)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    analyzer = DocumentDataAnalyzer(config)
    
    # 1. ë°ì´í„° ë¡œë“œ
    analyzer.load_data()
    
    # 2. í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
    label_dist = analyzer.analyze_class_distribution()
    analyzer.plot_class_distribution(label_dist)
    
    # 3. ì´ë¯¸ì§€ ë¶„ì„
    analyzer.analyze_image_dimensions()
    analyzer.plot_image_analysis()
    
    # 4. í´ë˜ìŠ¤ë³„ íŠ¹ì„± ë¶„ì„
    class_stats = analyzer.analyze_class_characteristics()
    
    # 5. ë°ì´í„° ë¶„í• 
    train_df, val_df = analyzer.stratified_split(test_size=0.2)
    
    # 6. ê²°ê³¼ ì €ì¥
    if train_df is not None and val_df is not None:
        analyzer.save_results(train_df, val_df)
    
    # 7. ì¢…í•© ë¦¬í¬íŠ¸
    analyzer.generate_summary_report()
    
    print("\nğŸ‰ EDA ì™„ë£Œ!")

if __name__ == "__main__":
    main()